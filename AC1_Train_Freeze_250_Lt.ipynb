{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/My_Main_Project_Lt-/blob/main/AC1_Train_Freeze_250_Lt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เรียกใช้ CSV"
      ],
      "metadata": {
        "id": "ow7eWoNw6U-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8o_VVNXzcL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "be4621df-3b82-499c-a234-6ea5a1b78f62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/All_File_Lt/Data/All_Data_Lt.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "mbLFqTO1ze9O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "867ce9e6-297a-4e24-f1d5-7e46c265955e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person Class_Age+Gender Class_Age  Class_0-18  Age(year)  \\\n",
              "0           1           1             Y07F       Y07           0          7   \n",
              "1           2           1             Y07F       Y07           0          7   \n",
              "2           3           2             Y07F       Y07           0          7   \n",
              "3           4           2             Y07F       Y07           0          7   \n",
              "4           5           3             Y07F       Y07           0          7   \n",
              "...       ...         ...              ...       ...         ...        ...   \n",
              "4745      121          77             Y25M       Y25          18         25   \n",
              "4746      122          78             Y25M       Y25          18         25   \n",
              "4747      123          78             Y25M       Y25          18         25   \n",
              "4748      124          79             Y25M       Y25          18         25   \n",
              "4749      125          79             Y25M       Y25          18         25   \n",
              "\n",
              "      Class_0-1       Filename  \\\n",
              "0             0         V1.jpg   \n",
              "1             0    Flip_V1.jpg   \n",
              "2             0         V2.jpg   \n",
              "3             0    Flip_V2.jpg   \n",
              "4             0         V3.jpg   \n",
              "...         ...            ...   \n",
              "4745          1  Flip_J463.jpg   \n",
              "4746          1       J464.jpg   \n",
              "4747          1  Flip_J464.jpg   \n",
              "4748          1       J465.jpg   \n",
              "4749          1  Flip_J465.jpg   \n",
              "\n",
              "                                          Path_filename     Sex Floder  \n",
              "0     /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female   Both  \n",
              "1     /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female   Both  \n",
              "2     /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female   Both  \n",
              "3     /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female   Both  \n",
              "4     /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female   Both  \n",
              "...                                                 ...     ...    ...  \n",
              "4745  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...    Male   Both  \n",
              "4746  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...    Male   Both  \n",
              "4747  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...    Male   Both  \n",
              "4748  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...    Male   Both  \n",
              "4749  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...    Male   Both  \n",
              "\n",
              "[4750 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0c1d210-ad46-4dec-9905-d80b167ea236\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person</th>\n",
              "      <th>Class_Age+Gender</th>\n",
              "      <th>Class_Age</th>\n",
              "      <th>Class_0-18</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class_0-1</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>V3.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4745</th>\n",
              "      <td>121</td>\n",
              "      <td>77</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_J463.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4746</th>\n",
              "      <td>122</td>\n",
              "      <td>78</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4747</th>\n",
              "      <td>123</td>\n",
              "      <td>78</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4748</th>\n",
              "      <td>124</td>\n",
              "      <td>79</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4749</th>\n",
              "      <td>125</td>\n",
              "      <td>79</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4750 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0c1d210-ad46-4dec-9905-d80b167ea236')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c0c1d210-ad46-4dec-9905-d80b167ea236 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c0c1d210-ad46-4dec-9905-d80b167ea236');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "5qxePnnn7TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ],
      "metadata": {
        "id": "RooqSdBc7QHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 250\n",
        "NUM_TRAIN = 2850\n",
        "NUM_TEST = 950\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "f2557440-aa07-4899-f2fb-d534d6f40d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 1085, done.\u001b[K\n",
            "remote: Counting objects: 100% (248/248), done.\u001b[K\n",
            "remote: Compressing objects: 100% (127/127), done.\u001b[K\n",
            "remote: Total 1085 (delta 124), reused 241 (delta 121), pack-reused 837\u001b[K\n",
            "Receiving objects: 100% (1085/1085), 14.09 MiB | 10.65 MiB/s, done.\n",
            "Resolving deltas: 100% (621/621), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "Gqg_EUxrKkcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "uhCmH24AKmQ4",
        "outputId": "7ef89de2-42fd-4a3e-99f7-76978b636f64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "id": "IIWHby0gKpEq",
        "outputId": "db653c29-d84a-44a4-ecd8-a5c2a4170456",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(19, activation='softmax', name=\"fc_out\"))"
      ],
      "metadata": {
        "id": "yWNKfQUt5rga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "NadBB12251jh",
        "outputId": "d9b804d0-7fa1-4137-bfc8-49041c509da9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 4,031,887\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "GepWq3yy53t5",
        "outputId": "7edd7188-6bc9-4130-c38e-96b8503bc239",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 213\n",
            "This is the number of trainable layers after freezing the conv base: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "D-CwVu9LrNkg",
        "outputId": "23a30404-7c95-41f9-8faa-a24d067bc2e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 24,339\n",
            "Non-trainable params: 4,049,564\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Valodation และ Test"
      ],
      "metadata": {
        "id": "J36J9EAE7qSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = df[df['Fig_Age'].between(1,75)]\n",
        "val = df[df['Fig_Age'].between(76,100)]"
      ],
      "metadata": {
        "id": "nqCFbjRQ3okB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/My Drive/All_File_Lt/TVT_All_Lt\"\n",
        "os.chdir(DATA_PATH)\n",
        "train_dir = os.path.join(DATA_PATH, 'train')\n",
        "print(train_dir)\n",
        "validation_dir = os.path.join(DATA_PATH, 'validation')\n",
        "print(validation_dir)"
      ],
      "metadata": {
        "id": "GsjQKrdqrQ4g",
        "outputId": "9d5e3759-fbc8-41bd-9c1e-21485cf75faa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/All_File_Lt/TVT_All_Lt/train\n",
            "/content/drive/My Drive/All_File_Lt/TVT_All_Lt/validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Train"
      ],
      "metadata": {
        "id": "bWEnlTSwazL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe = train,\n",
        "        directory = train_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Age',\n",
        "        class_mode = 'categorical',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe = val,\n",
        "        directory = validation_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Age',\n",
        "        class_mode = 'categorical',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)"
      ],
      "metadata": {
        "id": "xGPrsn9no_pa",
        "outputId": "3e5cacb2-02ee-4346-a5c9-bddaada11033",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2850 validated image filenames belonging to 19 classes.\n",
            "Found 950 validated image filenames belonging to 19 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=2e-5),\n",
        "              metrics=['acc'])\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "N6qUmmF856ZE",
        "outputId": "db5d750c-56c9-42b4-dd97-6f1f3678527d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "178/178 [==============================] - 549s 3s/step - loss: 4.6068 - acc: 0.0512 - val_loss: 3.8196 - val_acc: 0.0625\n",
            "Epoch 2/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 4.0982 - acc: 0.0558 - val_loss: 3.6113 - val_acc: 0.0763\n",
            "Epoch 3/250\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 3.9834 - acc: 0.0568 - val_loss: 3.5366 - val_acc: 0.0752\n",
            "Epoch 4/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.9669 - acc: 0.0593 - val_loss: 3.4647 - val_acc: 0.0742\n",
            "Epoch 5/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.8699 - acc: 0.0699 - val_loss: 3.4238 - val_acc: 0.0826\n",
            "Epoch 6/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 3.8432 - acc: 0.0649 - val_loss: 3.3847 - val_acc: 0.0890\n",
            "Epoch 7/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 3.7964 - acc: 0.0737 - val_loss: 3.3774 - val_acc: 0.0953\n",
            "Epoch 8/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 3.7084 - acc: 0.0819 - val_loss: 3.3122 - val_acc: 0.0953\n",
            "Epoch 9/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.7092 - acc: 0.0836 - val_loss: 3.2814 - val_acc: 0.0985\n",
            "Epoch 10/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.6631 - acc: 0.0843 - val_loss: 3.2635 - val_acc: 0.1006\n",
            "Epoch 11/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 3.6570 - acc: 0.0734 - val_loss: 3.2277 - val_acc: 0.1017\n",
            "Epoch 12/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.5730 - acc: 0.0829 - val_loss: 3.2215 - val_acc: 0.0953\n",
            "Epoch 13/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 3.6069 - acc: 0.0857 - val_loss: 3.1658 - val_acc: 0.1059\n",
            "Epoch 14/250\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 3.5956 - acc: 0.0857 - val_loss: 3.1289 - val_acc: 0.1081\n",
            "Epoch 15/250\n",
            "178/178 [==============================] - 19s 103ms/step - loss: 3.4811 - acc: 0.1009 - val_loss: 3.1313 - val_acc: 0.1102\n",
            "Epoch 16/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 3.5047 - acc: 0.0875 - val_loss: 3.0909 - val_acc: 0.1186\n",
            "Epoch 17/250\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 3.4555 - acc: 0.0910 - val_loss: 3.0791 - val_acc: 0.1186\n",
            "Epoch 18/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.4252 - acc: 0.0988 - val_loss: 3.0825 - val_acc: 0.1091\n",
            "Epoch 19/250\n",
            "178/178 [==============================] - 24s 129ms/step - loss: 3.4706 - acc: 0.1013 - val_loss: 3.0833 - val_acc: 0.1155\n",
            "Epoch 20/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 3.3967 - acc: 0.1101 - val_loss: 3.0777 - val_acc: 0.1165\n",
            "Epoch 21/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 3.3566 - acc: 0.0981 - val_loss: 3.0354 - val_acc: 0.1112\n",
            "Epoch 22/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 3.3225 - acc: 0.1041 - val_loss: 2.9996 - val_acc: 0.1176\n",
            "Epoch 23/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.4033 - acc: 0.0988 - val_loss: 2.9866 - val_acc: 0.1186\n",
            "Epoch 24/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 3.3429 - acc: 0.1087 - val_loss: 2.9660 - val_acc: 0.1218\n",
            "Epoch 25/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 3.3415 - acc: 0.1034 - val_loss: 2.9729 - val_acc: 0.1155\n",
            "Epoch 26/250\n",
            "178/178 [==============================] - 24s 136ms/step - loss: 3.3050 - acc: 0.1055 - val_loss: 2.9456 - val_acc: 0.1239\n",
            "Epoch 27/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.2875 - acc: 0.1129 - val_loss: 2.9293 - val_acc: 0.1271\n",
            "Epoch 28/250\n",
            "178/178 [==============================] - 23s 130ms/step - loss: 3.2810 - acc: 0.1122 - val_loss: 2.9230 - val_acc: 0.1271\n",
            "Epoch 29/250\n",
            "178/178 [==============================] - 20s 109ms/step - loss: 3.2626 - acc: 0.1104 - val_loss: 2.9070 - val_acc: 0.1229\n",
            "Epoch 30/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 3.2142 - acc: 0.1193 - val_loss: 2.8958 - val_acc: 0.1250\n",
            "Epoch 31/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.2620 - acc: 0.1062 - val_loss: 2.8796 - val_acc: 0.1292\n",
            "Epoch 32/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 3.1907 - acc: 0.1193 - val_loss: 2.8750 - val_acc: 0.1314\n",
            "Epoch 33/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 3.2153 - acc: 0.1136 - val_loss: 2.8763 - val_acc: 0.1324\n",
            "Epoch 34/250\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 3.2081 - acc: 0.1210 - val_loss: 2.8685 - val_acc: 0.1314\n",
            "Epoch 35/250\n",
            "178/178 [==============================] - 23s 130ms/step - loss: 3.2447 - acc: 0.1066 - val_loss: 2.8533 - val_acc: 0.1292\n",
            "Epoch 36/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 3.1941 - acc: 0.1277 - val_loss: 2.8433 - val_acc: 0.1356\n",
            "Epoch 37/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.1595 - acc: 0.1253 - val_loss: 2.8323 - val_acc: 0.1367\n",
            "Epoch 38/250\n",
            "178/178 [==============================] - 25s 136ms/step - loss: 3.1518 - acc: 0.1136 - val_loss: 2.8235 - val_acc: 0.1314\n",
            "Epoch 39/250\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 3.1630 - acc: 0.1242 - val_loss: 2.8252 - val_acc: 0.1303\n",
            "Epoch 40/250\n",
            "178/178 [==============================] - 23s 130ms/step - loss: 3.1653 - acc: 0.1267 - val_loss: 2.7970 - val_acc: 0.1356\n",
            "Epoch 41/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.0824 - acc: 0.1337 - val_loss: 2.7999 - val_acc: 0.1367\n",
            "Epoch 42/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 3.1290 - acc: 0.1214 - val_loss: 2.7995 - val_acc: 0.1356\n",
            "Epoch 43/250\n",
            "178/178 [==============================] - 25s 135ms/step - loss: 3.1321 - acc: 0.1284 - val_loss: 2.7733 - val_acc: 0.1367\n",
            "Epoch 44/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.1588 - acc: 0.1263 - val_loss: 2.7687 - val_acc: 0.1419\n",
            "Epoch 45/250\n",
            "178/178 [==============================] - 19s 104ms/step - loss: 3.1151 - acc: 0.1323 - val_loss: 2.7714 - val_acc: 0.1388\n",
            "Epoch 46/250\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 3.0944 - acc: 0.1214 - val_loss: 2.7824 - val_acc: 0.1335\n",
            "Epoch 47/250\n",
            "178/178 [==============================] - 20s 109ms/step - loss: 3.1152 - acc: 0.1239 - val_loss: 2.7607 - val_acc: 0.1377\n",
            "Epoch 48/250\n",
            "178/178 [==============================] - 24s 129ms/step - loss: 3.0469 - acc: 0.1387 - val_loss: 2.7800 - val_acc: 0.1377\n",
            "Epoch 49/250\n",
            "178/178 [==============================] - 25s 136ms/step - loss: 3.0550 - acc: 0.1334 - val_loss: 2.7807 - val_acc: 0.1324\n",
            "Epoch 50/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 3.0733 - acc: 0.1239 - val_loss: 2.7489 - val_acc: 0.1367\n",
            "Epoch 51/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 3.0393 - acc: 0.1387 - val_loss: 2.7576 - val_acc: 0.1388\n",
            "Epoch 52/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 3.0355 - acc: 0.1344 - val_loss: 2.7494 - val_acc: 0.1419\n",
            "Epoch 53/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 3.0186 - acc: 0.1344 - val_loss: 2.7367 - val_acc: 0.1451\n",
            "Epoch 54/250\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 3.0943 - acc: 0.1263 - val_loss: 2.7318 - val_acc: 0.1430\n",
            "Epoch 55/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 3.0266 - acc: 0.1351 - val_loss: 2.7186 - val_acc: 0.1451\n",
            "Epoch 56/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 3.0089 - acc: 0.1408 - val_loss: 2.7233 - val_acc: 0.1419\n",
            "Epoch 57/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 3.0311 - acc: 0.1373 - val_loss: 2.7292 - val_acc: 0.1419\n",
            "Epoch 58/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 3.0060 - acc: 0.1316 - val_loss: 2.7075 - val_acc: 0.1451\n",
            "Epoch 59/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.9866 - acc: 0.1362 - val_loss: 2.6895 - val_acc: 0.1547\n",
            "Epoch 60/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.9912 - acc: 0.1306 - val_loss: 2.6873 - val_acc: 0.1462\n",
            "Epoch 61/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 3.0133 - acc: 0.1288 - val_loss: 2.6974 - val_acc: 0.1451\n",
            "Epoch 62/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.9793 - acc: 0.1422 - val_loss: 2.6844 - val_acc: 0.1419\n",
            "Epoch 63/250\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 2.9727 - acc: 0.1327 - val_loss: 2.7065 - val_acc: 0.1398\n",
            "Epoch 64/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.9620 - acc: 0.1415 - val_loss: 2.6859 - val_acc: 0.1451\n",
            "Epoch 65/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.9730 - acc: 0.1478 - val_loss: 2.6774 - val_acc: 0.1419\n",
            "Epoch 66/250\n",
            "178/178 [==============================] - 19s 103ms/step - loss: 3.0046 - acc: 0.1366 - val_loss: 2.6931 - val_acc: 0.1409\n",
            "Epoch 67/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.9595 - acc: 0.1478 - val_loss: 2.6727 - val_acc: 0.1398\n",
            "Epoch 68/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.9315 - acc: 0.1443 - val_loss: 2.6817 - val_acc: 0.1367\n",
            "Epoch 69/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.9450 - acc: 0.1415 - val_loss: 2.6748 - val_acc: 0.1441\n",
            "Epoch 70/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.9473 - acc: 0.1521 - val_loss: 2.6647 - val_acc: 0.1451\n",
            "Epoch 71/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.9159 - acc: 0.1471 - val_loss: 2.6509 - val_acc: 0.1441\n",
            "Epoch 72/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.9531 - acc: 0.1408 - val_loss: 2.6581 - val_acc: 0.1472\n",
            "Epoch 73/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.9148 - acc: 0.1531 - val_loss: 2.6751 - val_acc: 0.1472\n",
            "Epoch 74/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.9313 - acc: 0.1341 - val_loss: 2.6634 - val_acc: 0.1462\n",
            "Epoch 75/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.9006 - acc: 0.1387 - val_loss: 2.6540 - val_acc: 0.1398\n",
            "Epoch 76/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.9679 - acc: 0.1468 - val_loss: 2.6559 - val_acc: 0.1441\n",
            "Epoch 77/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.8931 - acc: 0.1507 - val_loss: 2.6488 - val_acc: 0.1483\n",
            "Epoch 78/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.9101 - acc: 0.1496 - val_loss: 2.6456 - val_acc: 0.1557\n",
            "Epoch 79/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.8865 - acc: 0.1426 - val_loss: 2.6305 - val_acc: 0.1483\n",
            "Epoch 80/250\n",
            "178/178 [==============================] - 25s 136ms/step - loss: 2.9303 - acc: 0.1443 - val_loss: 2.6432 - val_acc: 0.1515\n",
            "Epoch 81/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.8605 - acc: 0.1521 - val_loss: 2.6328 - val_acc: 0.1515\n",
            "Epoch 82/250\n",
            "178/178 [==============================] - 23s 130ms/step - loss: 2.8800 - acc: 0.1570 - val_loss: 2.6345 - val_acc: 0.1568\n",
            "Epoch 83/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.8626 - acc: 0.1471 - val_loss: 2.6229 - val_acc: 0.1483\n",
            "Epoch 84/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.8620 - acc: 0.1496 - val_loss: 2.6288 - val_acc: 0.1494\n",
            "Epoch 85/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.8399 - acc: 0.1489 - val_loss: 2.6323 - val_acc: 0.1451\n",
            "Epoch 86/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.8565 - acc: 0.1567 - val_loss: 2.6199 - val_acc: 0.1472\n",
            "Epoch 87/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.8640 - acc: 0.1510 - val_loss: 2.6286 - val_acc: 0.1494\n",
            "Epoch 88/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.8758 - acc: 0.1415 - val_loss: 2.6200 - val_acc: 0.1515\n",
            "Epoch 89/250\n",
            "178/178 [==============================] - 20s 109ms/step - loss: 2.8718 - acc: 0.1531 - val_loss: 2.6218 - val_acc: 0.1525\n",
            "Epoch 90/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.8528 - acc: 0.1553 - val_loss: 2.6231 - val_acc: 0.1472\n",
            "Epoch 91/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.8347 - acc: 0.1475 - val_loss: 2.6340 - val_acc: 0.1547\n",
            "Epoch 92/250\n",
            "178/178 [==============================] - 20s 108ms/step - loss: 2.8291 - acc: 0.1535 - val_loss: 2.6032 - val_acc: 0.1525\n",
            "Epoch 93/250\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 2.8504 - acc: 0.1447 - val_loss: 2.6186 - val_acc: 0.1536\n",
            "Epoch 94/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.8237 - acc: 0.1627 - val_loss: 2.6324 - val_acc: 0.1504\n",
            "Epoch 95/250\n",
            "178/178 [==============================] - 20s 109ms/step - loss: 2.8228 - acc: 0.1528 - val_loss: 2.6082 - val_acc: 0.1589\n",
            "Epoch 96/250\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 2.8054 - acc: 0.1538 - val_loss: 2.5975 - val_acc: 0.1568\n",
            "Epoch 97/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.8249 - acc: 0.1549 - val_loss: 2.5966 - val_acc: 0.1568\n",
            "Epoch 98/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.8542 - acc: 0.1464 - val_loss: 2.5996 - val_acc: 0.1536\n",
            "Epoch 99/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.8358 - acc: 0.1563 - val_loss: 2.6013 - val_acc: 0.1578\n",
            "Epoch 100/250\n",
            "178/178 [==============================] - 20s 108ms/step - loss: 2.8218 - acc: 0.1482 - val_loss: 2.5996 - val_acc: 0.1547\n",
            "Epoch 101/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.8142 - acc: 0.1609 - val_loss: 2.6000 - val_acc: 0.1589\n",
            "Epoch 102/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.7963 - acc: 0.1634 - val_loss: 2.5902 - val_acc: 0.1631\n",
            "Epoch 103/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.7852 - acc: 0.1535 - val_loss: 2.5894 - val_acc: 0.1600\n",
            "Epoch 104/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.8440 - acc: 0.1577 - val_loss: 2.5875 - val_acc: 0.1568\n",
            "Epoch 105/250\n",
            "178/178 [==============================] - 19s 103ms/step - loss: 2.8155 - acc: 0.1507 - val_loss: 2.5795 - val_acc: 0.1578\n",
            "Epoch 106/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.8168 - acc: 0.1496 - val_loss: 2.5873 - val_acc: 0.1663\n",
            "Epoch 107/250\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 2.8026 - acc: 0.1595 - val_loss: 2.5904 - val_acc: 0.1557\n",
            "Epoch 108/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.8431 - acc: 0.1496 - val_loss: 2.5939 - val_acc: 0.1536\n",
            "Epoch 109/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.7739 - acc: 0.1549 - val_loss: 2.5844 - val_acc: 0.1663\n",
            "Epoch 110/250\n",
            "178/178 [==============================] - 20s 110ms/step - loss: 2.7997 - acc: 0.1538 - val_loss: 2.5852 - val_acc: 0.1610\n",
            "Epoch 111/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.7595 - acc: 0.1531 - val_loss: 2.5808 - val_acc: 0.1578\n",
            "Epoch 112/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.8044 - acc: 0.1528 - val_loss: 2.5748 - val_acc: 0.1589\n",
            "Epoch 113/250\n",
            "178/178 [==============================] - 19s 104ms/step - loss: 2.7391 - acc: 0.1644 - val_loss: 2.5824 - val_acc: 0.1600\n",
            "Epoch 114/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.7765 - acc: 0.1595 - val_loss: 2.5683 - val_acc: 0.1674\n",
            "Epoch 115/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.7601 - acc: 0.1549 - val_loss: 2.5724 - val_acc: 0.1578\n",
            "Epoch 116/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.7639 - acc: 0.1588 - val_loss: 2.5721 - val_acc: 0.1621\n",
            "Epoch 117/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.7639 - acc: 0.1531 - val_loss: 2.5796 - val_acc: 0.1568\n",
            "Epoch 118/250\n",
            "178/178 [==============================] - 25s 136ms/step - loss: 2.7932 - acc: 0.1486 - val_loss: 2.5871 - val_acc: 0.1610\n",
            "Epoch 119/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.7249 - acc: 0.1634 - val_loss: 2.5767 - val_acc: 0.1600\n",
            "Epoch 120/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.7586 - acc: 0.1644 - val_loss: 2.5704 - val_acc: 0.1621\n",
            "Epoch 121/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.7310 - acc: 0.1606 - val_loss: 2.5634 - val_acc: 0.1621\n",
            "Epoch 122/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.7451 - acc: 0.1662 - val_loss: 2.5722 - val_acc: 0.1695\n",
            "Epoch 123/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.7537 - acc: 0.1524 - val_loss: 2.5803 - val_acc: 0.1653\n",
            "Epoch 124/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.7523 - acc: 0.1725 - val_loss: 2.5704 - val_acc: 0.1621\n",
            "Epoch 125/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.7282 - acc: 0.1461 - val_loss: 2.5707 - val_acc: 0.1674\n",
            "Epoch 126/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.7298 - acc: 0.1620 - val_loss: 2.5726 - val_acc: 0.1536\n",
            "Epoch 127/250\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 2.7274 - acc: 0.1553 - val_loss: 2.5592 - val_acc: 0.1631\n",
            "Epoch 128/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.7394 - acc: 0.1609 - val_loss: 2.5563 - val_acc: 0.1589\n",
            "Epoch 129/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.7501 - acc: 0.1556 - val_loss: 2.5642 - val_acc: 0.1621\n",
            "Epoch 130/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.6615 - acc: 0.1676 - val_loss: 2.5680 - val_acc: 0.1684\n",
            "Epoch 131/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.7281 - acc: 0.1623 - val_loss: 2.5645 - val_acc: 0.1610\n",
            "Epoch 132/250\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 2.7157 - acc: 0.1613 - val_loss: 2.5702 - val_acc: 0.1557\n",
            "Epoch 133/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.7281 - acc: 0.1651 - val_loss: 2.5509 - val_acc: 0.1600\n",
            "Epoch 134/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.6975 - acc: 0.1708 - val_loss: 2.5686 - val_acc: 0.1663\n",
            "Epoch 135/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.6997 - acc: 0.1722 - val_loss: 2.5490 - val_acc: 0.1674\n",
            "Epoch 136/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.6895 - acc: 0.1711 - val_loss: 2.5577 - val_acc: 0.1642\n",
            "Epoch 137/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.7340 - acc: 0.1637 - val_loss: 2.5475 - val_acc: 0.1610\n",
            "Epoch 138/250\n",
            "178/178 [==============================] - 20s 109ms/step - loss: 2.6938 - acc: 0.1658 - val_loss: 2.5521 - val_acc: 0.1600\n",
            "Epoch 139/250\n",
            "178/178 [==============================] - 19s 104ms/step - loss: 2.7514 - acc: 0.1549 - val_loss: 2.5495 - val_acc: 0.1621\n",
            "Epoch 140/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.7061 - acc: 0.1616 - val_loss: 2.5423 - val_acc: 0.1674\n",
            "Epoch 141/250\n",
            "178/178 [==============================] - 23s 130ms/step - loss: 2.6898 - acc: 0.1722 - val_loss: 2.5417 - val_acc: 0.1727\n",
            "Epoch 142/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.6939 - acc: 0.1701 - val_loss: 2.5643 - val_acc: 0.1610\n",
            "Epoch 143/250\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 2.6939 - acc: 0.1690 - val_loss: 2.5414 - val_acc: 0.1663\n",
            "Epoch 144/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.6930 - acc: 0.1750 - val_loss: 2.5472 - val_acc: 0.1631\n",
            "Epoch 145/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.6869 - acc: 0.1651 - val_loss: 2.5428 - val_acc: 0.1674\n",
            "Epoch 146/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.6516 - acc: 0.1778 - val_loss: 2.5433 - val_acc: 0.1589\n",
            "Epoch 147/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.6680 - acc: 0.1669 - val_loss: 2.5509 - val_acc: 0.1695\n",
            "Epoch 148/250\n",
            "178/178 [==============================] - 24s 136ms/step - loss: 2.6479 - acc: 0.1736 - val_loss: 2.5503 - val_acc: 0.1631\n",
            "Epoch 149/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.6439 - acc: 0.1722 - val_loss: 2.5410 - val_acc: 0.1695\n",
            "Epoch 150/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.6728 - acc: 0.1598 - val_loss: 2.5502 - val_acc: 0.1642\n",
            "Epoch 151/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.7037 - acc: 0.1531 - val_loss: 2.5506 - val_acc: 0.1674\n",
            "Epoch 152/250\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 2.6482 - acc: 0.1761 - val_loss: 2.5322 - val_acc: 0.1663\n",
            "Epoch 153/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.6692 - acc: 0.1680 - val_loss: 2.5423 - val_acc: 0.1706\n",
            "Epoch 154/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.6456 - acc: 0.1768 - val_loss: 2.5414 - val_acc: 0.1663\n",
            "Epoch 155/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.6370 - acc: 0.1722 - val_loss: 2.5347 - val_acc: 0.1663\n",
            "Epoch 156/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.6670 - acc: 0.1814 - val_loss: 2.5406 - val_acc: 0.1674\n",
            "Epoch 157/250\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 2.6613 - acc: 0.1680 - val_loss: 2.5391 - val_acc: 0.1684\n",
            "Epoch 158/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.6245 - acc: 0.1733 - val_loss: 2.5504 - val_acc: 0.1684\n",
            "Epoch 159/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.6818 - acc: 0.1687 - val_loss: 2.5436 - val_acc: 0.1663\n",
            "Epoch 160/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.6547 - acc: 0.1648 - val_loss: 2.5432 - val_acc: 0.1695\n",
            "Epoch 161/250\n",
            "178/178 [==============================] - 25s 137ms/step - loss: 2.6378 - acc: 0.1694 - val_loss: 2.5449 - val_acc: 0.1737\n",
            "Epoch 162/250\n",
            "178/178 [==============================] - 20s 112ms/step - loss: 2.6468 - acc: 0.1729 - val_loss: 2.5571 - val_acc: 0.1706\n",
            "Epoch 163/250\n",
            "178/178 [==============================] - 25s 138ms/step - loss: 2.6534 - acc: 0.1722 - val_loss: 2.5543 - val_acc: 0.1727\n",
            "Epoch 164/250\n",
            "178/178 [==============================] - 26s 142ms/step - loss: 2.6357 - acc: 0.1838 - val_loss: 2.5409 - val_acc: 0.1769\n",
            "Epoch 165/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.6478 - acc: 0.1690 - val_loss: 2.5386 - val_acc: 0.1674\n",
            "Epoch 166/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.6385 - acc: 0.1701 - val_loss: 2.5466 - val_acc: 0.1653\n",
            "Epoch 167/250\n",
            "178/178 [==============================] - 23s 130ms/step - loss: 2.6653 - acc: 0.1725 - val_loss: 2.5261 - val_acc: 0.1716\n",
            "Epoch 168/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.6217 - acc: 0.1743 - val_loss: 2.5615 - val_acc: 0.1706\n",
            "Epoch 169/250\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 2.6373 - acc: 0.1658 - val_loss: 2.5672 - val_acc: 0.1684\n",
            "Epoch 170/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.5893 - acc: 0.1718 - val_loss: 2.5614 - val_acc: 0.1684\n",
            "Epoch 171/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.6051 - acc: 0.1764 - val_loss: 2.5576 - val_acc: 0.1663\n",
            "Epoch 172/250\n",
            "178/178 [==============================] - 19s 104ms/step - loss: 2.6207 - acc: 0.1733 - val_loss: 2.5369 - val_acc: 0.1653\n",
            "Epoch 173/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.6047 - acc: 0.1796 - val_loss: 2.5299 - val_acc: 0.1695\n",
            "Epoch 174/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.6215 - acc: 0.1831 - val_loss: 2.5429 - val_acc: 0.1674\n",
            "Epoch 175/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.6141 - acc: 0.1733 - val_loss: 2.5375 - val_acc: 0.1663\n",
            "Epoch 176/250\n",
            "178/178 [==============================] - 24s 129ms/step - loss: 2.5891 - acc: 0.1736 - val_loss: 2.5390 - val_acc: 0.1663\n",
            "Epoch 177/250\n",
            "178/178 [==============================] - 25s 135ms/step - loss: 2.6303 - acc: 0.1708 - val_loss: 2.5468 - val_acc: 0.1727\n",
            "Epoch 178/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.5866 - acc: 0.1733 - val_loss: 2.5393 - val_acc: 0.1727\n",
            "Epoch 179/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.5982 - acc: 0.1683 - val_loss: 2.5492 - val_acc: 0.1663\n",
            "Epoch 180/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.6356 - acc: 0.1673 - val_loss: 2.5402 - val_acc: 0.1684\n",
            "Epoch 181/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.5999 - acc: 0.1824 - val_loss: 2.5383 - val_acc: 0.1674\n",
            "Epoch 182/250\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 2.5701 - acc: 0.1849 - val_loss: 2.5345 - val_acc: 0.1737\n",
            "Epoch 183/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.5993 - acc: 0.1761 - val_loss: 2.5474 - val_acc: 0.1674\n",
            "Epoch 184/250\n",
            "178/178 [==============================] - 23s 130ms/step - loss: 2.6149 - acc: 0.1722 - val_loss: 2.5332 - val_acc: 0.1695\n",
            "Epoch 185/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.5965 - acc: 0.1725 - val_loss: 2.5282 - val_acc: 0.1758\n",
            "Epoch 186/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.5819 - acc: 0.1810 - val_loss: 2.5382 - val_acc: 0.1695\n",
            "Epoch 187/250\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 2.5884 - acc: 0.1828 - val_loss: 2.5339 - val_acc: 0.1716\n",
            "Epoch 188/250\n",
            "178/178 [==============================] - 20s 111ms/step - loss: 2.5994 - acc: 0.1754 - val_loss: 2.5480 - val_acc: 0.1769\n",
            "Epoch 189/250\n",
            "178/178 [==============================] - 20s 109ms/step - loss: 2.5916 - acc: 0.1842 - val_loss: 2.5285 - val_acc: 0.1780\n",
            "Epoch 190/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.6327 - acc: 0.1711 - val_loss: 2.5231 - val_acc: 0.1748\n",
            "Epoch 191/250\n",
            "178/178 [==============================] - 20s 107ms/step - loss: 2.5767 - acc: 0.1856 - val_loss: 2.5485 - val_acc: 0.1769\n",
            "Epoch 192/250\n",
            "178/178 [==============================] - 25s 138ms/step - loss: 2.5526 - acc: 0.1817 - val_loss: 2.5282 - val_acc: 0.1706\n",
            "Epoch 193/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.6194 - acc: 0.1669 - val_loss: 2.5434 - val_acc: 0.1727\n",
            "Epoch 194/250\n",
            "178/178 [==============================] - 19s 106ms/step - loss: 2.5771 - acc: 0.1821 - val_loss: 2.5164 - val_acc: 0.1801\n",
            "Epoch 195/250\n",
            "178/178 [==============================] - 20s 111ms/step - loss: 2.5925 - acc: 0.1708 - val_loss: 2.5404 - val_acc: 0.1727\n",
            "Epoch 196/250\n",
            "178/178 [==============================] - 19s 104ms/step - loss: 2.5762 - acc: 0.1877 - val_loss: 2.5434 - val_acc: 0.1769\n",
            "Epoch 197/250\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 2.5761 - acc: 0.1828 - val_loss: 2.5452 - val_acc: 0.1706\n",
            "Epoch 198/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.5899 - acc: 0.1778 - val_loss: 2.5317 - val_acc: 0.1716\n",
            "Epoch 199/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.5848 - acc: 0.1740 - val_loss: 2.5234 - val_acc: 0.1727\n",
            "Epoch 200/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.5763 - acc: 0.1793 - val_loss: 2.5267 - val_acc: 0.1780\n",
            "Epoch 201/250\n",
            "178/178 [==============================] - 21s 112ms/step - loss: 2.5596 - acc: 0.1888 - val_loss: 2.5394 - val_acc: 0.1727\n",
            "Epoch 202/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.5681 - acc: 0.1796 - val_loss: 2.5420 - val_acc: 0.1684\n",
            "Epoch 203/250\n",
            "178/178 [==============================] - 19s 106ms/step - loss: 2.5531 - acc: 0.1870 - val_loss: 2.5328 - val_acc: 0.1674\n",
            "Epoch 204/250\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 2.5598 - acc: 0.1874 - val_loss: 2.5360 - val_acc: 0.1737\n",
            "Epoch 205/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.5753 - acc: 0.1782 - val_loss: 2.5402 - val_acc: 0.1748\n",
            "Epoch 206/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.5912 - acc: 0.1775 - val_loss: 2.5431 - val_acc: 0.1674\n",
            "Epoch 207/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.5856 - acc: 0.1757 - val_loss: 2.5194 - val_acc: 0.1716\n",
            "Epoch 208/250\n",
            "178/178 [==============================] - 20s 111ms/step - loss: 2.5439 - acc: 0.1838 - val_loss: 2.5239 - val_acc: 0.1737\n",
            "Epoch 209/250\n",
            "178/178 [==============================] - 25s 136ms/step - loss: 2.5419 - acc: 0.1824 - val_loss: 2.5387 - val_acc: 0.1695\n",
            "Epoch 210/250\n",
            "178/178 [==============================] - 25s 137ms/step - loss: 2.5175 - acc: 0.1860 - val_loss: 2.5280 - val_acc: 0.1811\n",
            "Epoch 211/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.5468 - acc: 0.1905 - val_loss: 2.5200 - val_acc: 0.1706\n",
            "Epoch 212/250\n",
            "178/178 [==============================] - 19s 104ms/step - loss: 2.5206 - acc: 0.1884 - val_loss: 2.5228 - val_acc: 0.1748\n",
            "Epoch 213/250\n",
            "178/178 [==============================] - 25s 136ms/step - loss: 2.5695 - acc: 0.1902 - val_loss: 2.5292 - val_acc: 0.1801\n",
            "Epoch 214/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.5537 - acc: 0.1881 - val_loss: 2.5345 - val_acc: 0.1758\n",
            "Epoch 215/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.5558 - acc: 0.1733 - val_loss: 2.5249 - val_acc: 0.1737\n",
            "Epoch 216/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.5282 - acc: 0.1976 - val_loss: 2.5300 - val_acc: 0.1769\n",
            "Epoch 217/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.5339 - acc: 0.1849 - val_loss: 2.5246 - val_acc: 0.1748\n",
            "Epoch 218/250\n",
            "178/178 [==============================] - 25s 136ms/step - loss: 2.5182 - acc: 0.1909 - val_loss: 2.5262 - val_acc: 0.1727\n",
            "Epoch 219/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.5102 - acc: 0.1898 - val_loss: 2.5239 - val_acc: 0.1769\n",
            "Epoch 220/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.5435 - acc: 0.1743 - val_loss: 2.5227 - val_acc: 0.1716\n",
            "Epoch 221/250\n",
            "178/178 [==============================] - 19s 104ms/step - loss: 2.5351 - acc: 0.1842 - val_loss: 2.5270 - val_acc: 0.1706\n",
            "Epoch 222/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.5524 - acc: 0.1863 - val_loss: 2.5352 - val_acc: 0.1758\n",
            "Epoch 223/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.5338 - acc: 0.1831 - val_loss: 2.5348 - val_acc: 0.1695\n",
            "Epoch 224/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.5245 - acc: 0.1895 - val_loss: 2.5473 - val_acc: 0.1695\n",
            "Epoch 225/250\n",
            "178/178 [==============================] - 19s 106ms/step - loss: 2.5131 - acc: 0.1895 - val_loss: 2.5319 - val_acc: 0.1695\n",
            "Epoch 226/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.4856 - acc: 0.1884 - val_loss: 2.5257 - val_acc: 0.1833\n",
            "Epoch 227/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.5199 - acc: 0.1824 - val_loss: 2.5343 - val_acc: 0.1737\n",
            "Epoch 228/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.5156 - acc: 0.1828 - val_loss: 2.5245 - val_acc: 0.1748\n",
            "Epoch 229/250\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 2.5327 - acc: 0.1796 - val_loss: 2.5380 - val_acc: 0.1716\n",
            "Epoch 230/250\n",
            "178/178 [==============================] - 19s 107ms/step - loss: 2.4779 - acc: 0.1969 - val_loss: 2.5302 - val_acc: 0.1706\n",
            "Epoch 231/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.4949 - acc: 0.1965 - val_loss: 2.5376 - val_acc: 0.1674\n",
            "Epoch 232/250\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 2.5249 - acc: 0.1838 - val_loss: 2.5221 - val_acc: 0.1748\n",
            "Epoch 233/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.5444 - acc: 0.1909 - val_loss: 2.5283 - val_acc: 0.1674\n",
            "Epoch 234/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.5213 - acc: 0.1835 - val_loss: 2.5282 - val_acc: 0.1706\n",
            "Epoch 235/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.5189 - acc: 0.1870 - val_loss: 2.5255 - val_acc: 0.1748\n",
            "Epoch 236/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.5064 - acc: 0.1860 - val_loss: 2.5297 - val_acc: 0.1727\n",
            "Epoch 237/250\n",
            "178/178 [==============================] - 25s 136ms/step - loss: 2.5136 - acc: 0.1909 - val_loss: 2.5174 - val_acc: 0.1748\n",
            "Epoch 238/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.4847 - acc: 0.1983 - val_loss: 2.5146 - val_acc: 0.1790\n",
            "Epoch 239/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.5013 - acc: 0.1965 - val_loss: 2.5272 - val_acc: 0.1811\n",
            "Epoch 240/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.5136 - acc: 0.1898 - val_loss: 2.5260 - val_acc: 0.1780\n",
            "Epoch 241/250\n",
            "178/178 [==============================] - 20s 109ms/step - loss: 2.4931 - acc: 0.1930 - val_loss: 2.5521 - val_acc: 0.1653\n",
            "Epoch 242/250\n",
            "178/178 [==============================] - 20s 108ms/step - loss: 2.4950 - acc: 0.1916 - val_loss: 2.5318 - val_acc: 0.1727\n",
            "Epoch 243/250\n",
            "178/178 [==============================] - 20s 109ms/step - loss: 2.5325 - acc: 0.1761 - val_loss: 2.5366 - val_acc: 0.1653\n",
            "Epoch 244/250\n",
            "178/178 [==============================] - 20s 108ms/step - loss: 2.5009 - acc: 0.1905 - val_loss: 2.5282 - val_acc: 0.1706\n",
            "Epoch 245/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.4890 - acc: 0.1888 - val_loss: 2.5383 - val_acc: 0.1780\n",
            "Epoch 246/250\n",
            "178/178 [==============================] - 23s 130ms/step - loss: 2.4510 - acc: 0.1888 - val_loss: 2.5359 - val_acc: 0.1769\n",
            "Epoch 247/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.4473 - acc: 0.2057 - val_loss: 2.5260 - val_acc: 0.1758\n",
            "Epoch 248/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.4860 - acc: 0.1937 - val_loss: 2.5253 - val_acc: 0.1769\n",
            "Epoch 249/250\n",
            "178/178 [==============================] - 19s 106ms/step - loss: 2.4764 - acc: 0.1958 - val_loss: 2.5350 - val_acc: 0.1758\n",
            "Epoch 250/250\n",
            "178/178 [==============================] - 20s 109ms/step - loss: 2.5159 - acc: 0.1828 - val_loss: 2.5211 - val_acc: 0.1716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'ro', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'ro', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "42e29d2a-974d-494e-f78a-07aa3141cca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model\n"
      ],
      "metadata": {
        "id": "R19IJQSYoW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/MyDrive/All_File_Lt/Model/Classification/All_Age/AC1_Freeze_250_Lt.h5')"
      ],
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/11_รอบแรก_Flimpano_Female125_250.h5')"
      ],
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xlsuaFIUVriv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}