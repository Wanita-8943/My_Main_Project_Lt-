{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/My_Main_Project_Lt-/blob/main/M1_Train_Freeze_250_Lt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เรียกใช้ CSV"
      ],
      "metadata": {
        "id": "ow7eWoNw6U-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8o_VVNXzcL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "4d412a0f-579b-4978-c298-25c1145c4956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/All_File_Lt/Data/All_Data_Lt.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "mbLFqTO1ze9O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "outputId": "639282ce-f847-4553-9bf3-30982cdeec45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person Class_Age+Gender Class_Age  Class_0-18  Age(year)  \\\n",
              "0           1           1             Y07F       Y07           0          7   \n",
              "1           2           1             Y07F       Y07           0          7   \n",
              "2           3           2             Y07F       Y07           0          7   \n",
              "3           4           2             Y07F       Y07           0          7   \n",
              "4           5           3             Y07F       Y07           0          7   \n",
              "...       ...         ...              ...       ...         ...        ...   \n",
              "4745      121          77             Y25M       Y25          18         25   \n",
              "4746      122          78             Y25M       Y25          18         25   \n",
              "4747      123          78             Y25M       Y25          18         25   \n",
              "4748      124          79             Y25M       Y25          18         25   \n",
              "4749      125          79             Y25M       Y25          18         25   \n",
              "\n",
              "      Class_0-1       Filename  \\\n",
              "0             0         V1.jpg   \n",
              "1             0    Flip_V1.jpg   \n",
              "2             0         V2.jpg   \n",
              "3             0    Flip_V2.jpg   \n",
              "4             0         V3.jpg   \n",
              "...         ...            ...   \n",
              "4745          1  Flip_J463.jpg   \n",
              "4746          1       J464.jpg   \n",
              "4747          1  Flip_J464.jpg   \n",
              "4748          1       J465.jpg   \n",
              "4749          1  Flip_J465.jpg   \n",
              "\n",
              "                                          Path_filename     Sex Floder  \n",
              "0     /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female   Both  \n",
              "1     /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female   Both  \n",
              "2     /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female   Both  \n",
              "3     /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female   Both  \n",
              "4     /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female   Both  \n",
              "...                                                 ...     ...    ...  \n",
              "4745  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...    Male   Both  \n",
              "4746  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...    Male   Both  \n",
              "4747  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...    Male   Both  \n",
              "4748  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...    Male   Both  \n",
              "4749  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...    Male   Both  \n",
              "\n",
              "[4750 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02b5dbb2-746c-4e2c-8f36-4a1233660395\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person</th>\n",
              "      <th>Class_Age+Gender</th>\n",
              "      <th>Class_Age</th>\n",
              "      <th>Class_0-18</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class_0-1</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>V3.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4745</th>\n",
              "      <td>121</td>\n",
              "      <td>77</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_J463.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4746</th>\n",
              "      <td>122</td>\n",
              "      <td>78</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4747</th>\n",
              "      <td>123</td>\n",
              "      <td>78</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4748</th>\n",
              "      <td>124</td>\n",
              "      <td>79</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4749</th>\n",
              "      <td>125</td>\n",
              "      <td>79</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4750 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02b5dbb2-746c-4e2c-8f36-4a1233660395')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02b5dbb2-746c-4e2c-8f36-4a1233660395 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02b5dbb2-746c-4e2c-8f36-4a1233660395');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "5qxePnnn7TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ],
      "metadata": {
        "id": "RooqSdBc7QHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 250\n",
        "NUM_TRAIN = 1425\n",
        "NUM_TEST = 475\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "75e03a92-dbad-4f7a-96df-dc8c5dc2b6ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 1085, done.\u001b[K\n",
            "remote: Counting objects: 100% (248/248), done.\u001b[K\n",
            "remote: Compressing objects: 100% (127/127), done.\u001b[K\n",
            "remote: Total 1085 (delta 124), reused 241 (delta 121), pack-reused 837\u001b[K\n",
            "Receiving objects: 100% (1085/1085), 14.09 MiB | 17.39 MiB/s, done.\n",
            "Resolving deltas: 100% (621/621), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB3 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "Gqg_EUxrKkcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "uhCmH24AKmQ4",
        "outputId": "289e584c-3b0b-4f25-96e5-db47543995cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b3_imagenet_1000_notop.h5\n",
            "43966704/43966704 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "id": "IIWHby0gKpEq",
        "outputId": "b7589803-6d39-460a-b243-9de6b337f2e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 40)   1080        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 40)  160         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 40)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 40)  360         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 40)  160         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 40)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 40)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 10)     410         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 10)     0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 40)     440         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 40)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 40)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 24)   960         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 24)  96          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 75, 75, 24)  216         ['batch_normalization_2[0][0]']  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 24)  96          ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 24)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 24)     0           ['swish_3[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 1, 1, 6)      150         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 1, 1, 6)      0           ['conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 24)     168         ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 24)     0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 75, 75, 24)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_3[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 75, 75, 24)   576         ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 75, 75, 24)  96          ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 75, 75, 24)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 75, 75, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 75, 75, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 75, 75, 144)  576        ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 75, 75, 144)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_5[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_6[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 1, 1, 6)      0           ['conv2d_8[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 144)    1008        ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_6[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 38, 38, 32)   4608        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 32)  128         ['conv2d_10[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 192)  6144        ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 192)  768        ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 38, 38, 192)  0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 38, 38, 192)  1728       ['swish_8[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 192)  768        ['depthwise_conv2d_3[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 192)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 192)    0           ['swish_9[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 1, 1, 8)      1544        ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 1, 1, 8)      0           ['conv2d_12[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 192)    1728        ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 192)    0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 38, 38, 192)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_9[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 38, 38, 32)   6144        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 38, 38, 32)  128         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 38, 38, 32)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 38, 38, 32)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 38, 38, 192)  6144        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 38, 38, 192)  768        ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 38, 38, 192)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 38, 38, 192)  1728       ['swish_11[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 38, 38, 192)  768        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 38, 38, 192)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 192)    0           ['swish_12[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 1, 1, 8)      1544        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 1, 1, 8)      0           ['conv2d_16[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 192)    1728        ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 192)    0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 38, 38, 192)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_12[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 38, 38, 32)   6144        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 38, 38, 32)  128         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 38, 38, 32)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 38, 38, 32)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 38, 38, 192)  6144        ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 38, 38, 192)  768        ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 38, 38, 192)  0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 19, 19, 192)  4800       ['swish_14[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 192)  768        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 192)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 192)    0           ['swish_15[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 1, 1, 8)      1544        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 1, 1, 8)      0           ['conv2d_20[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 192)    1728        ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 192)    0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 19, 19, 192)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_15[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 19, 19, 48)   9216        ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 19, 19, 48)  192         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 19, 19, 288)  13824       ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 19, 19, 288)  1152       ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 19, 19, 288)  0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 19, 19, 288)  7200       ['swish_17[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 19, 19, 288)  1152       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 19, 19, 288)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 288)    0           ['swish_18[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 1, 1, 12)     3468        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 1, 1, 12)     0           ['conv2d_24[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 288)    3744        ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 288)    0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 19, 19, 288)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_18[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 19, 19, 48)   13824       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 19, 19, 48)  192         ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 19, 19, 48)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 19, 19, 48)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 19, 19, 288)  13824       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 19, 19, 288)  1152       ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 19, 19, 288)  0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 19, 19, 288)  7200       ['swish_20[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 19, 19, 288)  1152       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 19, 19, 288)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 288)    0           ['swish_21[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 1, 1, 12)     3468        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 1, 1, 12)     0           ['conv2d_28[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 288)    3744        ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 288)    0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 19, 19, 288)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_21[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 19, 19, 48)   13824       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 19, 19, 48)  192         ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 19, 19, 48)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 19, 19, 48)   0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 19, 19, 288)  13824       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 19, 19, 288)  1152       ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 19, 19, 288)  0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 288)  2592       ['swish_23[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 288)  1152       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 288)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 288)    0           ['swish_24[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 1, 1, 12)     3468        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 1, 1, 12)     0           ['conv2d_32[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 288)    3744        ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 288)    0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 288)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_24[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 10, 10, 96)   27648       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 96)  384         ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 576)  55296       ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 576)  2304       ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 10, 10, 576)  0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 576)  5184       ['swish_26[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 576)  2304       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 576)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 576)    0           ['swish_27[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 1, 1, 24)     13848       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 1, 1, 24)     0           ['conv2d_36[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 576)    14400       ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 576)    0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 576)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_27[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 10, 10, 96)   55296       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 96)  384         ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 96)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 96)   0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 576)  55296       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 576)  2304       ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 10, 10, 576)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 576)  5184       ['swish_29[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 576)  2304       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 576)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 576)    0           ['swish_30[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 1, 1, 24)     13848       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 1, 1, 24)     0           ['conv2d_40[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 576)    14400       ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 576)    0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 576)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_30[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 10, 10, 96)   55296       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 96)  384         ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 10, 10, 96)   0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 10, 10, 96)   0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 576)  55296       ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 576)  2304       ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 10, 10, 576)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 10, 10, 576)  5184       ['swish_32[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 576)  2304       ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 576)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 576)    0           ['swish_33[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 1, 1, 24)     13848       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 1, 1, 24)     0           ['conv2d_44[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 576)    14400       ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 576)    0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 10, 10, 576)  0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_33[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 10, 10, 96)   55296       ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 10, 10, 96)  384         ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 10, 10, 96)   0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 10, 10, 96)   0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 10, 10, 576)  55296       ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 10, 10, 576)  2304       ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 10, 10, 576)  0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 10, 10, 576)  5184       ['swish_35[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 10, 10, 576)  2304       ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 10, 10, 576)  0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 576)    0           ['swish_36[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 1, 1, 24)     13848       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 1, 1, 24)     0           ['conv2d_48[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 576)    14400       ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 576)    0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 10, 10, 576)  0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_36[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 10, 10, 96)   55296       ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 10, 10, 96)  384         ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 10, 10, 96)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 10, 10, 96)   0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 10, 10, 576)  55296       ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 10, 10, 576)  2304       ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 10, 10, 576)  0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 10, 10, 576)  14400      ['swish_38[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 10, 10, 576)  2304       ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 10, 10, 576)  0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 576)    0           ['swish_39[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 1, 1, 24)     13848       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 1, 1, 24)     0           ['conv2d_52[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 576)    14400       ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 576)    0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 10, 10, 576)  0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_39[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 10, 10, 136)  78336       ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 10, 10, 136)  544        ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 10, 10, 816)  110976      ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 10, 10, 816)  3264       ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 10, 10, 816)  0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 10, 10, 816)  20400      ['swish_41[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 10, 10, 816)  3264       ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 10, 10, 816)  0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 816)    0           ['swish_42[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 1, 1, 34)     27778       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 1, 1, 34)     0           ['conv2d_56[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 816)    28560       ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 816)    0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 10, 10, 816)  0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_42[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 10, 10, 136)  110976      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 10, 10, 136)  544        ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_9 (DropConnect)   (None, 10, 10, 136)  0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 10, 10, 136)  0           ['drop_connect_9[0][0]',         \n",
            "                                                                  'batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 10, 10, 816)  110976      ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 10, 10, 816)  3264       ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 10, 10, 816)  0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 10, 10, 816)  20400      ['swish_44[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 10, 10, 816)  3264       ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 10, 10, 816)  0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 816)    0           ['swish_45[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 1, 1, 34)     27778       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 1, 1, 34)     0           ['conv2d_60[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 816)    28560       ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 816)    0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 10, 10, 816)  0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_45[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 10, 10, 136)  110976      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 10, 10, 136)  544        ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_10 (DropConnect)  (None, 10, 10, 136)  0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 10, 10, 136)  0           ['drop_connect_10[0][0]',        \n",
            "                                                                  'add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 10, 10, 816)  110976      ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 10, 10, 816)  3264       ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 10, 10, 816)  0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_16 (Depthwise  (None, 10, 10, 816)  20400      ['swish_47[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 10, 10, 816)  3264       ['depthwise_conv2d_16[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 10, 10, 816)  0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_16 (Lambda)             (None, 1, 1, 816)    0           ['swish_48[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 1, 1, 34)     27778       ['lambda_16[0][0]']              \n",
            "                                                                                                  \n",
            " swish_49 (Swish)               (None, 1, 1, 34)     0           ['conv2d_64[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 1, 1, 816)    28560       ['swish_49[0][0]']               \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 1, 1, 816)    0           ['conv2d_65[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_16 (Multiply)         (None, 10, 10, 816)  0           ['activation_16[0][0]',          \n",
            "                                                                  'swish_48[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 10, 10, 136)  110976      ['multiply_16[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 10, 10, 136)  544        ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_11 (DropConnect)  (None, 10, 10, 136)  0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 10, 10, 136)  0           ['drop_connect_11[0][0]',        \n",
            "                                                                  'add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 10, 10, 816)  110976      ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 10, 10, 816)  3264       ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_50 (Swish)               (None, 10, 10, 816)  0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_17 (Depthwise  (None, 10, 10, 816)  20400      ['swish_50[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 10, 10, 816)  3264       ['depthwise_conv2d_17[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_51 (Swish)               (None, 10, 10, 816)  0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_17 (Lambda)             (None, 1, 1, 816)    0           ['swish_51[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 1, 1, 34)     27778       ['lambda_17[0][0]']              \n",
            "                                                                                                  \n",
            " swish_52 (Swish)               (None, 1, 1, 34)     0           ['conv2d_68[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 1, 1, 816)    28560       ['swish_52[0][0]']               \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 1, 1, 816)    0           ['conv2d_69[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_17 (Multiply)         (None, 10, 10, 816)  0           ['activation_17[0][0]',          \n",
            "                                                                  'swish_51[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 10, 10, 136)  110976      ['multiply_17[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 10, 10, 136)  544        ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_12 (DropConnect)  (None, 10, 10, 136)  0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 10, 10, 136)  0           ['drop_connect_12[0][0]',        \n",
            "                                                                  'add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 10, 10, 816)  110976      ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 10, 10, 816)  3264       ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_53 (Swish)               (None, 10, 10, 816)  0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_18 (Depthwise  (None, 5, 5, 816)   20400       ['swish_53[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 5, 5, 816)   3264        ['depthwise_conv2d_18[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_54 (Swish)               (None, 5, 5, 816)    0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_18 (Lambda)             (None, 1, 1, 816)    0           ['swish_54[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 1, 1, 34)     27778       ['lambda_18[0][0]']              \n",
            "                                                                                                  \n",
            " swish_55 (Swish)               (None, 1, 1, 34)     0           ['conv2d_72[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 1, 1, 816)    28560       ['swish_55[0][0]']               \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 1, 1, 816)    0           ['conv2d_73[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_18 (Multiply)         (None, 5, 5, 816)    0           ['activation_18[0][0]',          \n",
            "                                                                  'swish_54[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 5, 5, 232)    189312      ['multiply_18[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 5, 5, 232)   928         ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 5, 5, 1392)   322944      ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 5, 5, 1392)  5568        ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_56 (Swish)               (None, 5, 5, 1392)   0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_19 (Depthwise  (None, 5, 5, 1392)  34800       ['swish_56[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 5, 5, 1392)  5568        ['depthwise_conv2d_19[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_57 (Swish)               (None, 5, 5, 1392)   0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_19 (Lambda)             (None, 1, 1, 1392)   0           ['swish_57[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 1, 1, 58)     80794       ['lambda_19[0][0]']              \n",
            "                                                                                                  \n",
            " swish_58 (Swish)               (None, 1, 1, 58)     0           ['conv2d_76[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 1, 1, 1392)   82128       ['swish_58[0][0]']               \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 1, 1, 1392)   0           ['conv2d_77[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_19 (Multiply)         (None, 5, 5, 1392)   0           ['activation_19[0][0]',          \n",
            "                                                                  'swish_57[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 5, 5, 232)    322944      ['multiply_19[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 5, 5, 232)   928         ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_13 (DropConnect)  (None, 5, 5, 232)    0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 5, 5, 232)    0           ['drop_connect_13[0][0]',        \n",
            "                                                                  'batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 5, 5, 1392)   322944      ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 5, 5, 1392)  5568        ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_59 (Swish)               (None, 5, 5, 1392)   0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_20 (Depthwise  (None, 5, 5, 1392)  34800       ['swish_59[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 5, 5, 1392)  5568        ['depthwise_conv2d_20[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_60 (Swish)               (None, 5, 5, 1392)   0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_20 (Lambda)             (None, 1, 1, 1392)   0           ['swish_60[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 1, 1, 58)     80794       ['lambda_20[0][0]']              \n",
            "                                                                                                  \n",
            " swish_61 (Swish)               (None, 1, 1, 58)     0           ['conv2d_80[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 1, 1, 1392)   82128       ['swish_61[0][0]']               \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 1, 1, 1392)   0           ['conv2d_81[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_20 (Multiply)         (None, 5, 5, 1392)   0           ['activation_20[0][0]',          \n",
            "                                                                  'swish_60[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 5, 5, 232)    322944      ['multiply_20[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 5, 5, 232)   928         ['conv2d_82[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_14 (DropConnect)  (None, 5, 5, 232)    0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 5, 5, 232)    0           ['drop_connect_14[0][0]',        \n",
            "                                                                  'add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 5, 5, 1392)   322944      ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 5, 5, 1392)  5568        ['conv2d_83[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_62 (Swish)               (None, 5, 5, 1392)   0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_21 (Depthwise  (None, 5, 5, 1392)  34800       ['swish_62[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 5, 5, 1392)  5568        ['depthwise_conv2d_21[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_63 (Swish)               (None, 5, 5, 1392)   0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_21 (Lambda)             (None, 1, 1, 1392)   0           ['swish_63[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 1, 1, 58)     80794       ['lambda_21[0][0]']              \n",
            "                                                                                                  \n",
            " swish_64 (Swish)               (None, 1, 1, 58)     0           ['conv2d_84[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 1, 1, 1392)   82128       ['swish_64[0][0]']               \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 1, 1, 1392)   0           ['conv2d_85[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_21 (Multiply)         (None, 5, 5, 1392)   0           ['activation_21[0][0]',          \n",
            "                                                                  'swish_63[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 5, 5, 232)    322944      ['multiply_21[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 5, 5, 232)   928         ['conv2d_86[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_15 (DropConnect)  (None, 5, 5, 232)    0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 5, 5, 232)    0           ['drop_connect_15[0][0]',        \n",
            "                                                                  'add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 5, 5, 1392)   322944      ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 5, 5, 1392)  5568        ['conv2d_87[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_65 (Swish)               (None, 5, 5, 1392)   0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_22 (Depthwise  (None, 5, 5, 1392)  34800       ['swish_65[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 5, 5, 1392)  5568        ['depthwise_conv2d_22[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_66 (Swish)               (None, 5, 5, 1392)   0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_22 (Lambda)             (None, 1, 1, 1392)   0           ['swish_66[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 1, 1, 58)     80794       ['lambda_22[0][0]']              \n",
            "                                                                                                  \n",
            " swish_67 (Swish)               (None, 1, 1, 58)     0           ['conv2d_88[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 1, 1, 1392)   82128       ['swish_67[0][0]']               \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 1, 1, 1392)   0           ['conv2d_89[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_22 (Multiply)         (None, 5, 5, 1392)   0           ['activation_22[0][0]',          \n",
            "                                                                  'swish_66[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 5, 5, 232)    322944      ['multiply_22[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 5, 5, 232)   928         ['conv2d_90[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_16 (DropConnect)  (None, 5, 5, 232)    0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 5, 5, 232)    0           ['drop_connect_16[0][0]',        \n",
            "                                                                  'add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 5, 5, 1392)   322944      ['add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 5, 5, 1392)  5568        ['conv2d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_68 (Swish)               (None, 5, 5, 1392)   0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_23 (Depthwise  (None, 5, 5, 1392)  34800       ['swish_68[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 5, 5, 1392)  5568        ['depthwise_conv2d_23[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_69 (Swish)               (None, 5, 5, 1392)   0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_23 (Lambda)             (None, 1, 1, 1392)   0           ['swish_69[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 1, 1, 58)     80794       ['lambda_23[0][0]']              \n",
            "                                                                                                  \n",
            " swish_70 (Swish)               (None, 1, 1, 58)     0           ['conv2d_92[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 1, 1, 1392)   82128       ['swish_70[0][0]']               \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 1, 1, 1392)   0           ['conv2d_93[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_23 (Multiply)         (None, 5, 5, 1392)   0           ['activation_23[0][0]',          \n",
            "                                                                  'swish_69[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 5, 5, 232)    322944      ['multiply_23[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 5, 5, 232)   928         ['conv2d_94[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_17 (DropConnect)  (None, 5, 5, 232)    0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 5, 5, 232)    0           ['drop_connect_17[0][0]',        \n",
            "                                                                  'add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 5, 5, 1392)   322944      ['add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 5, 5, 1392)  5568        ['conv2d_95[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_71 (Swish)               (None, 5, 5, 1392)   0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_24 (Depthwise  (None, 5, 5, 1392)  12528       ['swish_71[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 5, 5, 1392)  5568        ['depthwise_conv2d_24[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_72 (Swish)               (None, 5, 5, 1392)   0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_24 (Lambda)             (None, 1, 1, 1392)   0           ['swish_72[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)             (None, 1, 1, 58)     80794       ['lambda_24[0][0]']              \n",
            "                                                                                                  \n",
            " swish_73 (Swish)               (None, 1, 1, 58)     0           ['conv2d_96[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)             (None, 1, 1, 1392)   82128       ['swish_73[0][0]']               \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 1, 1, 1392)   0           ['conv2d_97[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_24 (Multiply)         (None, 5, 5, 1392)   0           ['activation_24[0][0]',          \n",
            "                                                                  'swish_72[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)             (None, 5, 5, 384)    534528      ['multiply_24[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 5, 5, 384)   1536        ['conv2d_98[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)             (None, 5, 5, 2304)   884736      ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 5, 5, 2304)  9216        ['conv2d_99[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_74 (Swish)               (None, 5, 5, 2304)   0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_25 (Depthwise  (None, 5, 5, 2304)  20736       ['swish_74[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 5, 5, 2304)  9216        ['depthwise_conv2d_25[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_75 (Swish)               (None, 5, 5, 2304)   0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_25 (Lambda)             (None, 1, 1, 2304)   0           ['swish_75[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)            (None, 1, 1, 96)     221280      ['lambda_25[0][0]']              \n",
            "                                                                                                  \n",
            " swish_76 (Swish)               (None, 1, 1, 96)     0           ['conv2d_100[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)            (None, 1, 1, 2304)   223488      ['swish_76[0][0]']               \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 1, 1, 2304)   0           ['conv2d_101[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_25 (Multiply)         (None, 5, 5, 2304)   0           ['activation_25[0][0]',          \n",
            "                                                                  'swish_75[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)            (None, 5, 5, 384)    884736      ['multiply_25[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 5, 5, 384)   1536        ['conv2d_102[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_18 (DropConnect)  (None, 5, 5, 384)    0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " add_18 (Add)                   (None, 5, 5, 384)    0           ['drop_connect_18[0][0]',        \n",
            "                                                                  'batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)            (None, 5, 5, 1536)   589824      ['add_18[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 5, 5, 1536)  6144        ['conv2d_103[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_77 (Swish)               (None, 5, 5, 1536)   0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,783,528\n",
            "Trainable params: 10,696,232\n",
            "Non-trainable params: 87,296\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(19, activation='softmax', name=\"fc_out\"))"
      ],
      "metadata": {
        "id": "yWNKfQUt5rga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "NadBB12251jh",
        "outputId": "b2de24b3-3fb9-4f76-d8f9-cc3c8a870be4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b3 (Functional  (None, 5, 5, 1536)       10783528  \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1536)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1536)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                29203     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,812,731\n",
            "Trainable params: 10,725,435\n",
            "Non-trainable params: 87,296\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "GepWq3yy53t5",
        "outputId": "fdb65be4-eb86-4d24-fefa-5c899767e5d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 340\n",
            "This is the number of trainable layers after freezing the conv base: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "D-CwVu9LrNkg",
        "outputId": "8ff537df-2f44-4e1d-83df-a4c706c98241",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b3 (Functional  (None, 5, 5, 1536)       10783528  \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1536)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1536)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                29203     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,812,731\n",
            "Trainable params: 29,203\n",
            "Non-trainable params: 10,783,528\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Valodation และ Test"
      ],
      "metadata": {
        "id": "J36J9EAE7qSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Male = df[(df['Sex'] == 'Male')]"
      ],
      "metadata": {
        "id": "U7rydNfIr3Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Male"
      ],
      "metadata": {
        "id": "3LY0HbggsVJK",
        "outputId": "da21b093-d8b2-4113-903a-54f2a57f2173",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person Class_Age+Gender Class_Age  Class_0-18  Age(year)  \\\n",
              "2375        1           1             Y07M       Y07           0          7   \n",
              "2376        2           1             Y07M       Y07           0          7   \n",
              "2377        3           2             Y07M       Y07           0          7   \n",
              "2378        4           2             Y07M       Y07           0          7   \n",
              "2379        5           3             Y07M       Y07           0          7   \n",
              "...       ...         ...              ...       ...         ...        ...   \n",
              "4745      121          77             Y25M       Y25          18         25   \n",
              "4746      122          78             Y25M       Y25          18         25   \n",
              "4747      123          78             Y25M       Y25          18         25   \n",
              "4748      124          79             Y25M       Y25          18         25   \n",
              "4749      125          79             Y25M       Y25          18         25   \n",
              "\n",
              "      Class_0-1       Filename  \\\n",
              "2375          1       VV03.jpg   \n",
              "2376          1  Flip_VV03.jpg   \n",
              "2377          1       VV04.jpg   \n",
              "2378          1  Flip_VV04.jpg   \n",
              "2379          1       VV05.jpg   \n",
              "...         ...            ...   \n",
              "4745          1  Flip_J463.jpg   \n",
              "4746          1       J464.jpg   \n",
              "4747          1  Flip_J464.jpg   \n",
              "4748          1       J465.jpg   \n",
              "4749          1  Flip_J465.jpg   \n",
              "\n",
              "                                          Path_filename   Sex Floder  \n",
              "2375  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Male   Both  \n",
              "2376  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Male   Both  \n",
              "2377  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Male   Both  \n",
              "2378  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Male   Both  \n",
              "2379  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Male   Both  \n",
              "...                                                 ...   ...    ...  \n",
              "4745  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Male   Both  \n",
              "4746  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Male   Both  \n",
              "4747  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Male   Both  \n",
              "4748  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Male   Both  \n",
              "4749  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Male   Both  \n",
              "\n",
              "[2375 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c50be702-d505-4feb-bb95-1af96d7491f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person</th>\n",
              "      <th>Class_Age+Gender</th>\n",
              "      <th>Class_Age</th>\n",
              "      <th>Class_0-18</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class_0-1</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2375</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>VV03.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2376</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_VV03.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2377</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>VV04.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2378</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_VV04.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2379</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>VV05.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4745</th>\n",
              "      <td>121</td>\n",
              "      <td>77</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_J463.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4746</th>\n",
              "      <td>122</td>\n",
              "      <td>78</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4747</th>\n",
              "      <td>123</td>\n",
              "      <td>78</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4748</th>\n",
              "      <td>124</td>\n",
              "      <td>79</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4749</th>\n",
              "      <td>125</td>\n",
              "      <td>79</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2375 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c50be702-d505-4feb-bb95-1af96d7491f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c50be702-d505-4feb-bb95-1af96d7491f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c50be702-d505-4feb-bb95-1af96d7491f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = Male[Male['Fig_Age'].between(1,75)]\n",
        "val = Male[Male['Fig_Age'].between(76,100)]"
      ],
      "metadata": {
        "id": "nqCFbjRQ3okB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/My Drive/All_File_Lt/TVT_All_Lt\"\n",
        "os.chdir(DATA_PATH)\n",
        "train_dir = os.path.join(DATA_PATH, 'train')\n",
        "print(train_dir)\n",
        "validation_dir = os.path.join(DATA_PATH, 'validation')\n",
        "print(validation_dir)"
      ],
      "metadata": {
        "id": "GsjQKrdqrQ4g",
        "outputId": "9c2fdd19-11d3-4461-a54b-5c327195eb97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/All_File_Lt/TVT_All_Lt/train\n",
            "/content/drive/My Drive/All_File_Lt/TVT_All_Lt/validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Train"
      ],
      "metadata": {
        "id": "bWEnlTSwazL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe = train,\n",
        "        directory = train_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Age+Gender',\n",
        "        class_mode = 'categorical',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe = val,\n",
        "        directory = validation_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Age+Gender',\n",
        "        class_mode = 'categorical',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)"
      ],
      "metadata": {
        "id": "xGPrsn9no_pa",
        "outputId": "9b3414e9-d3cb-42f1-e4ef-1148529ffb53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1425 validated image filenames belonging to 19 classes.\n",
            "Found 475 validated image filenames belonging to 19 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=2e-5),\n",
        "              metrics=['acc'])\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "N6qUmmF856ZE",
        "outputId": "0252fb74-2c53-4f00-9138-63756518a98d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "89/89 [==============================] - 281s 3s/step - loss: 5.6667 - acc: 0.0454 - val_loss: 3.9783 - val_acc: 0.0409\n",
            "Epoch 2/250\n",
            "89/89 [==============================] - 12s 135ms/step - loss: 5.2492 - acc: 0.0539 - val_loss: 3.6469 - val_acc: 0.0474\n",
            "Epoch 3/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 4.8416 - acc: 0.0483 - val_loss: 3.4775 - val_acc: 0.0560\n",
            "Epoch 4/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 4.7193 - acc: 0.0603 - val_loss: 3.3922 - val_acc: 0.0797\n",
            "Epoch 5/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 4.7928 - acc: 0.0603 - val_loss: 3.3501 - val_acc: 0.0668\n",
            "Epoch 6/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 4.5552 - acc: 0.0511 - val_loss: 3.2892 - val_acc: 0.0819\n",
            "Epoch 7/250\n",
            "89/89 [==============================] - 11s 116ms/step - loss: 4.6972 - acc: 0.0525 - val_loss: 3.2679 - val_acc: 0.0819\n",
            "Epoch 8/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 4.4752 - acc: 0.0767 - val_loss: 3.2052 - val_acc: 0.0905\n",
            "Epoch 9/250\n",
            "89/89 [==============================] - 13s 145ms/step - loss: 4.5864 - acc: 0.0575 - val_loss: 3.1704 - val_acc: 0.0819\n",
            "Epoch 10/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 4.5483 - acc: 0.0610 - val_loss: 3.1457 - val_acc: 0.0948\n",
            "Epoch 11/250\n",
            "89/89 [==============================] - 12s 123ms/step - loss: 4.3685 - acc: 0.0688 - val_loss: 3.1174 - val_acc: 0.0905\n",
            "Epoch 12/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 4.3274 - acc: 0.0703 - val_loss: 3.0995 - val_acc: 0.0970\n",
            "Epoch 13/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 4.4400 - acc: 0.0703 - val_loss: 3.0684 - val_acc: 0.1056\n",
            "Epoch 14/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 4.3027 - acc: 0.0696 - val_loss: 3.0589 - val_acc: 0.0948\n",
            "Epoch 15/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 4.2410 - acc: 0.0731 - val_loss: 3.0312 - val_acc: 0.1056\n",
            "Epoch 16/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 4.3069 - acc: 0.0767 - val_loss: 3.0048 - val_acc: 0.1078\n",
            "Epoch 17/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 4.3176 - acc: 0.0667 - val_loss: 3.0100 - val_acc: 0.1078\n",
            "Epoch 18/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 4.1995 - acc: 0.0724 - val_loss: 3.0055 - val_acc: 0.1078\n",
            "Epoch 19/250\n",
            "89/89 [==============================] - 11s 117ms/step - loss: 4.2337 - acc: 0.0752 - val_loss: 2.9660 - val_acc: 0.1078\n",
            "Epoch 20/250\n",
            "89/89 [==============================] - 15s 166ms/step - loss: 4.1818 - acc: 0.0823 - val_loss: 2.9663 - val_acc: 0.1056\n",
            "Epoch 21/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 4.0803 - acc: 0.0752 - val_loss: 2.9266 - val_acc: 0.1121\n",
            "Epoch 22/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 4.0740 - acc: 0.0899 - val_loss: 2.9753 - val_acc: 0.1099\n",
            "Epoch 23/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 4.1058 - acc: 0.0823 - val_loss: 2.9165 - val_acc: 0.1121\n",
            "Epoch 24/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 4.1468 - acc: 0.0816 - val_loss: 2.9184 - val_acc: 0.1185\n",
            "Epoch 25/250\n",
            "89/89 [==============================] - 15s 166ms/step - loss: 4.1400 - acc: 0.0859 - val_loss: 2.9033 - val_acc: 0.1142\n",
            "Epoch 26/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 4.0759 - acc: 0.0837 - val_loss: 2.8851 - val_acc: 0.1099\n",
            "Epoch 27/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.9677 - acc: 0.0901 - val_loss: 2.8785 - val_acc: 0.1185\n",
            "Epoch 28/250\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 4.1028 - acc: 0.0752 - val_loss: 2.8867 - val_acc: 0.1164\n",
            "Epoch 29/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 4.0291 - acc: 0.0731 - val_loss: 2.8796 - val_acc: 0.1207\n",
            "Epoch 30/250\n",
            "89/89 [==============================] - 16s 169ms/step - loss: 3.9852 - acc: 0.0788 - val_loss: 2.8460 - val_acc: 0.1207\n",
            "Epoch 31/250\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 3.9190 - acc: 0.0958 - val_loss: 2.8460 - val_acc: 0.1250\n",
            "Epoch 32/250\n",
            "89/89 [==============================] - 15s 166ms/step - loss: 4.0172 - acc: 0.0930 - val_loss: 2.8399 - val_acc: 0.1228\n",
            "Epoch 33/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.9639 - acc: 0.0866 - val_loss: 2.8350 - val_acc: 0.1272\n",
            "Epoch 34/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.9322 - acc: 0.0901 - val_loss: 2.8364 - val_acc: 0.1315\n",
            "Epoch 35/250\n",
            "89/89 [==============================] - 16s 178ms/step - loss: 4.0287 - acc: 0.0816 - val_loss: 2.8225 - val_acc: 0.1293\n",
            "Epoch 36/250\n",
            "89/89 [==============================] - 13s 142ms/step - loss: 3.9419 - acc: 0.0816 - val_loss: 2.8134 - val_acc: 0.1315\n",
            "Epoch 37/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 3.8851 - acc: 0.0979 - val_loss: 2.7918 - val_acc: 0.1315\n",
            "Epoch 38/250\n",
            "89/89 [==============================] - 15s 169ms/step - loss: 3.9240 - acc: 0.0873 - val_loss: 2.7883 - val_acc: 0.1401\n",
            "Epoch 39/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.8221 - acc: 0.0894 - val_loss: 2.8033 - val_acc: 0.1315\n",
            "Epoch 40/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 3.8574 - acc: 0.0965 - val_loss: 2.7929 - val_acc: 0.1272\n",
            "Epoch 41/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.8033 - acc: 0.0908 - val_loss: 2.7839 - val_acc: 0.1336\n",
            "Epoch 42/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 3.8954 - acc: 0.0916 - val_loss: 2.7899 - val_acc: 0.1250\n",
            "Epoch 43/250\n",
            "89/89 [==============================] - 15s 168ms/step - loss: 3.8971 - acc: 0.0972 - val_loss: 2.7759 - val_acc: 0.1250\n",
            "Epoch 44/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.8032 - acc: 0.0923 - val_loss: 2.7774 - val_acc: 0.1358\n",
            "Epoch 45/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.7532 - acc: 0.1043 - val_loss: 2.7482 - val_acc: 0.1401\n",
            "Epoch 46/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 3.7983 - acc: 0.0979 - val_loss: 2.7438 - val_acc: 0.1466\n",
            "Epoch 47/250\n",
            "89/89 [==============================] - 15s 167ms/step - loss: 3.8370 - acc: 0.0873 - val_loss: 2.7505 - val_acc: 0.1487\n",
            "Epoch 48/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.8017 - acc: 0.0887 - val_loss: 2.7734 - val_acc: 0.1444\n",
            "Epoch 49/250\n",
            "89/89 [==============================] - 13s 142ms/step - loss: 3.7726 - acc: 0.0937 - val_loss: 2.7499 - val_acc: 0.1552\n",
            "Epoch 50/250\n",
            "89/89 [==============================] - 16s 179ms/step - loss: 3.8296 - acc: 0.0901 - val_loss: 2.7589 - val_acc: 0.1379\n",
            "Epoch 51/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.7840 - acc: 0.0979 - val_loss: 2.7620 - val_acc: 0.1466\n",
            "Epoch 52/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 3.7944 - acc: 0.0908 - val_loss: 2.7379 - val_acc: 0.1401\n",
            "Epoch 53/250\n",
            "89/89 [==============================] - 15s 166ms/step - loss: 3.8656 - acc: 0.0866 - val_loss: 2.7372 - val_acc: 0.1466\n",
            "Epoch 54/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.7149 - acc: 0.0958 - val_loss: 2.7356 - val_acc: 0.1444\n",
            "Epoch 55/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.7155 - acc: 0.0994 - val_loss: 2.7313 - val_acc: 0.1509\n",
            "Epoch 56/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.7479 - acc: 0.1043 - val_loss: 2.7388 - val_acc: 0.1509\n",
            "Epoch 57/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.7781 - acc: 0.1157 - val_loss: 2.7399 - val_acc: 0.1552\n",
            "Epoch 58/250\n",
            "89/89 [==============================] - 15s 165ms/step - loss: 3.6929 - acc: 0.1001 - val_loss: 2.7186 - val_acc: 0.1573\n",
            "Epoch 59/250\n",
            "89/89 [==============================] - 11s 116ms/step - loss: 3.6600 - acc: 0.1057 - val_loss: 2.7232 - val_acc: 0.1466\n",
            "Epoch 60/250\n",
            "89/89 [==============================] - 16s 168ms/step - loss: 3.6878 - acc: 0.1022 - val_loss: 2.7095 - val_acc: 0.1509\n",
            "Epoch 61/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.7396 - acc: 0.1086 - val_loss: 2.6985 - val_acc: 0.1552\n",
            "Epoch 62/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.7666 - acc: 0.1008 - val_loss: 2.6936 - val_acc: 0.1616\n",
            "Epoch 63/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.6526 - acc: 0.1185 - val_loss: 2.6932 - val_acc: 0.1552\n",
            "Epoch 64/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.7248 - acc: 0.0979 - val_loss: 2.7084 - val_acc: 0.1509\n",
            "Epoch 65/250\n",
            "89/89 [==============================] - 15s 164ms/step - loss: 3.6713 - acc: 0.0994 - val_loss: 2.6870 - val_acc: 0.1509\n",
            "Epoch 66/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.7139 - acc: 0.0994 - val_loss: 2.6875 - val_acc: 0.1422\n",
            "Epoch 67/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.6577 - acc: 0.1029 - val_loss: 2.6722 - val_acc: 0.1573\n",
            "Epoch 68/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.6737 - acc: 0.1157 - val_loss: 2.6828 - val_acc: 0.1616\n",
            "Epoch 69/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.6338 - acc: 0.1121 - val_loss: 2.6690 - val_acc: 0.1681\n",
            "Epoch 70/250\n",
            "89/89 [==============================] - 11s 117ms/step - loss: 3.6212 - acc: 0.1057 - val_loss: 2.6724 - val_acc: 0.1466\n",
            "Epoch 71/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.7053 - acc: 0.1022 - val_loss: 2.6661 - val_acc: 0.1616\n",
            "Epoch 72/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.5559 - acc: 0.1164 - val_loss: 2.6866 - val_acc: 0.1530\n",
            "Epoch 73/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.6177 - acc: 0.1086 - val_loss: 2.6622 - val_acc: 0.1552\n",
            "Epoch 74/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.5467 - acc: 0.1221 - val_loss: 2.6652 - val_acc: 0.1616\n",
            "Epoch 75/250\n",
            "89/89 [==============================] - 16s 169ms/step - loss: 3.6210 - acc: 0.1214 - val_loss: 2.6477 - val_acc: 0.1616\n",
            "Epoch 76/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.6391 - acc: 0.1093 - val_loss: 2.6528 - val_acc: 0.1552\n",
            "Epoch 77/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.5329 - acc: 0.1079 - val_loss: 2.6541 - val_acc: 0.1595\n",
            "Epoch 78/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.5728 - acc: 0.1121 - val_loss: 2.6527 - val_acc: 0.1595\n",
            "Epoch 79/250\n",
            "89/89 [==============================] - 16s 178ms/step - loss: 3.6780 - acc: 0.1207 - val_loss: 2.6431 - val_acc: 0.1573\n",
            "Epoch 80/250\n",
            "89/89 [==============================] - 15s 165ms/step - loss: 3.5710 - acc: 0.1192 - val_loss: 2.6431 - val_acc: 0.1444\n",
            "Epoch 81/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.6812 - acc: 0.1136 - val_loss: 2.6417 - val_acc: 0.1466\n",
            "Epoch 82/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.5206 - acc: 0.1299 - val_loss: 2.6403 - val_acc: 0.1466\n",
            "Epoch 83/250\n",
            "89/89 [==============================] - 14s 147ms/step - loss: 3.6709 - acc: 0.0937 - val_loss: 2.6430 - val_acc: 0.1530\n",
            "Epoch 84/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.4757 - acc: 0.1214 - val_loss: 2.6407 - val_acc: 0.1573\n",
            "Epoch 85/250\n",
            "89/89 [==============================] - 16s 178ms/step - loss: 3.6093 - acc: 0.1107 - val_loss: 2.6315 - val_acc: 0.1487\n",
            "Epoch 86/250\n",
            "89/89 [==============================] - 15s 168ms/step - loss: 3.5139 - acc: 0.1242 - val_loss: 2.6338 - val_acc: 0.1509\n",
            "Epoch 87/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.6285 - acc: 0.1157 - val_loss: 2.6365 - val_acc: 0.1659\n",
            "Epoch 88/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.5177 - acc: 0.1228 - val_loss: 2.6319 - val_acc: 0.1530\n",
            "Epoch 89/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 3.4990 - acc: 0.1093 - val_loss: 2.6538 - val_acc: 0.1444\n",
            "Epoch 90/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.5442 - acc: 0.1121 - val_loss: 2.6204 - val_acc: 0.1509\n",
            "Epoch 91/250\n",
            "89/89 [==============================] - 16s 167ms/step - loss: 3.4378 - acc: 0.1242 - val_loss: 2.6260 - val_acc: 0.1530\n",
            "Epoch 92/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.5634 - acc: 0.1093 - val_loss: 2.6541 - val_acc: 0.1466\n",
            "Epoch 93/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.5029 - acc: 0.1341 - val_loss: 2.6182 - val_acc: 0.1530\n",
            "Epoch 94/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.5322 - acc: 0.1121 - val_loss: 2.6312 - val_acc: 0.1509\n",
            "Epoch 95/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.5080 - acc: 0.1221 - val_loss: 2.6383 - val_acc: 0.1509\n",
            "Epoch 96/250\n",
            "89/89 [==============================] - 15s 166ms/step - loss: 3.4060 - acc: 0.1214 - val_loss: 2.6321 - val_acc: 0.1638\n",
            "Epoch 97/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.5408 - acc: 0.1121 - val_loss: 2.6407 - val_acc: 0.1530\n",
            "Epoch 98/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.5338 - acc: 0.1157 - val_loss: 2.6239 - val_acc: 0.1466\n",
            "Epoch 99/250\n",
            "89/89 [==============================] - 11s 123ms/step - loss: 3.5038 - acc: 0.1150 - val_loss: 2.6238 - val_acc: 0.1530\n",
            "Epoch 100/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 3.5222 - acc: 0.1235 - val_loss: 2.6241 - val_acc: 0.1552\n",
            "Epoch 101/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.3540 - acc: 0.1334 - val_loss: 2.6180 - val_acc: 0.1638\n",
            "Epoch 102/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.5032 - acc: 0.1079 - val_loss: 2.6286 - val_acc: 0.1509\n",
            "Epoch 103/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.3857 - acc: 0.1278 - val_loss: 2.6212 - val_acc: 0.1616\n",
            "Epoch 104/250\n",
            "89/89 [==============================] - 15s 165ms/step - loss: 3.5130 - acc: 0.1157 - val_loss: 2.5978 - val_acc: 0.1530\n",
            "Epoch 105/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.4239 - acc: 0.1292 - val_loss: 2.6026 - val_acc: 0.1616\n",
            "Epoch 106/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.4585 - acc: 0.1285 - val_loss: 2.6041 - val_acc: 0.1638\n",
            "Epoch 107/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.3901 - acc: 0.1228 - val_loss: 2.6015 - val_acc: 0.1509\n",
            "Epoch 108/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.5234 - acc: 0.1057 - val_loss: 2.6107 - val_acc: 0.1616\n",
            "Epoch 109/250\n",
            "89/89 [==============================] - 15s 165ms/step - loss: 3.4769 - acc: 0.1185 - val_loss: 2.5960 - val_acc: 0.1595\n",
            "Epoch 110/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.3767 - acc: 0.1136 - val_loss: 2.5896 - val_acc: 0.1487\n",
            "Epoch 111/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.3985 - acc: 0.1434 - val_loss: 2.5988 - val_acc: 0.1509\n",
            "Epoch 112/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.4071 - acc: 0.1136 - val_loss: 2.5857 - val_acc: 0.1552\n",
            "Epoch 113/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.5076 - acc: 0.1207 - val_loss: 2.5825 - val_acc: 0.1724\n",
            "Epoch 114/250\n",
            "89/89 [==============================] - 15s 166ms/step - loss: 3.4681 - acc: 0.1136 - val_loss: 2.5870 - val_acc: 0.1659\n",
            "Epoch 115/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.4313 - acc: 0.1136 - val_loss: 2.5930 - val_acc: 0.1638\n",
            "Epoch 116/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.4627 - acc: 0.1228 - val_loss: 2.5933 - val_acc: 0.1638\n",
            "Epoch 117/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 3.4231 - acc: 0.1242 - val_loss: 2.5780 - val_acc: 0.1552\n",
            "Epoch 118/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.4307 - acc: 0.1171 - val_loss: 2.5798 - val_acc: 0.1681\n",
            "Epoch 119/250\n",
            "89/89 [==============================] - 11s 122ms/step - loss: 3.3524 - acc: 0.1093 - val_loss: 2.5887 - val_acc: 0.1659\n",
            "Epoch 120/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 3.3961 - acc: 0.1263 - val_loss: 2.5741 - val_acc: 0.1573\n",
            "Epoch 121/250\n",
            "89/89 [==============================] - 11s 116ms/step - loss: 3.3114 - acc: 0.1285 - val_loss: 2.5806 - val_acc: 0.1530\n",
            "Epoch 122/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 3.3667 - acc: 0.1306 - val_loss: 2.6015 - val_acc: 0.1595\n",
            "Epoch 123/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.4184 - acc: 0.1348 - val_loss: 2.5744 - val_acc: 0.1595\n",
            "Epoch 124/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.3692 - acc: 0.1348 - val_loss: 2.5967 - val_acc: 0.1616\n",
            "Epoch 125/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.4479 - acc: 0.1107 - val_loss: 2.5761 - val_acc: 0.1530\n",
            "Epoch 126/250\n",
            "89/89 [==============================] - 16s 169ms/step - loss: 3.4181 - acc: 0.1242 - val_loss: 2.5588 - val_acc: 0.1638\n",
            "Epoch 127/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 3.3801 - acc: 0.1221 - val_loss: 2.5749 - val_acc: 0.1509\n",
            "Epoch 128/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.3905 - acc: 0.1334 - val_loss: 2.5812 - val_acc: 0.1573\n",
            "Epoch 129/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.3896 - acc: 0.1313 - val_loss: 2.5760 - val_acc: 0.1638\n",
            "Epoch 130/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.3423 - acc: 0.1136 - val_loss: 2.5743 - val_acc: 0.1573\n",
            "Epoch 131/250\n",
            "89/89 [==============================] - 16s 169ms/step - loss: 3.4416 - acc: 0.1285 - val_loss: 2.5668 - val_acc: 0.1595\n",
            "Epoch 132/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.2333 - acc: 0.1412 - val_loss: 2.5721 - val_acc: 0.1703\n",
            "Epoch 133/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.3139 - acc: 0.1235 - val_loss: 2.5699 - val_acc: 0.1681\n",
            "Epoch 134/250\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 3.2623 - acc: 0.1334 - val_loss: 2.5629 - val_acc: 0.1595\n",
            "Epoch 135/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.3655 - acc: 0.1136 - val_loss: 2.5846 - val_acc: 0.1638\n",
            "Epoch 136/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.3593 - acc: 0.1263 - val_loss: 2.5776 - val_acc: 0.1703\n",
            "Epoch 137/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 3.3465 - acc: 0.1483 - val_loss: 2.5734 - val_acc: 0.1552\n",
            "Epoch 138/250\n",
            "89/89 [==============================] - 15s 166ms/step - loss: 3.4411 - acc: 0.1171 - val_loss: 2.5840 - val_acc: 0.1573\n",
            "Epoch 139/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.3412 - acc: 0.1348 - val_loss: 2.5651 - val_acc: 0.1681\n",
            "Epoch 140/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.3435 - acc: 0.1313 - val_loss: 2.5638 - val_acc: 0.1767\n",
            "Epoch 141/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.3142 - acc: 0.1363 - val_loss: 2.5543 - val_acc: 0.1681\n",
            "Epoch 142/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.3822 - acc: 0.1299 - val_loss: 2.5612 - val_acc: 0.1616\n",
            "Epoch 143/250\n",
            "89/89 [==============================] - 15s 168ms/step - loss: 3.3127 - acc: 0.1221 - val_loss: 2.5713 - val_acc: 0.1616\n",
            "Epoch 144/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.2687 - acc: 0.1334 - val_loss: 2.5758 - val_acc: 0.1616\n",
            "Epoch 145/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.3472 - acc: 0.1185 - val_loss: 2.5665 - val_acc: 0.1703\n",
            "Epoch 146/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.3597 - acc: 0.1256 - val_loss: 2.5615 - val_acc: 0.1746\n",
            "Epoch 147/250\n",
            "89/89 [==============================] - 16s 179ms/step - loss: 3.3006 - acc: 0.1398 - val_loss: 2.5732 - val_acc: 0.1681\n",
            "Epoch 148/250\n",
            "89/89 [==============================] - 15s 165ms/step - loss: 3.3000 - acc: 0.1263 - val_loss: 2.5512 - val_acc: 0.1789\n",
            "Epoch 149/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 3.2666 - acc: 0.1363 - val_loss: 2.5573 - val_acc: 0.1767\n",
            "Epoch 150/250\n",
            "89/89 [==============================] - 11s 122ms/step - loss: 3.3322 - acc: 0.1178 - val_loss: 2.5455 - val_acc: 0.1638\n",
            "Epoch 151/250\n",
            "89/89 [==============================] - 15s 169ms/step - loss: 3.2737 - acc: 0.1285 - val_loss: 2.5751 - val_acc: 0.1509\n",
            "Epoch 152/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.2582 - acc: 0.1427 - val_loss: 2.5649 - val_acc: 0.1638\n",
            "Epoch 153/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.3002 - acc: 0.1285 - val_loss: 2.5624 - val_acc: 0.1681\n",
            "Epoch 154/250\n",
            "89/89 [==============================] - 16s 178ms/step - loss: 3.2662 - acc: 0.1235 - val_loss: 2.5516 - val_acc: 0.1616\n",
            "Epoch 155/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.2639 - acc: 0.1320 - val_loss: 2.5659 - val_acc: 0.1746\n",
            "Epoch 156/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.2253 - acc: 0.1427 - val_loss: 2.5326 - val_acc: 0.1746\n",
            "Epoch 157/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 3.2885 - acc: 0.1313 - val_loss: 2.5464 - val_acc: 0.1659\n",
            "Epoch 158/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.3811 - acc: 0.1285 - val_loss: 2.5548 - val_acc: 0.1659\n",
            "Epoch 159/250\n",
            "89/89 [==============================] - 11s 115ms/step - loss: 3.2246 - acc: 0.1419 - val_loss: 2.5695 - val_acc: 0.1681\n",
            "Epoch 160/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.3514 - acc: 0.1249 - val_loss: 2.5595 - val_acc: 0.1638\n",
            "Epoch 161/250\n",
            "89/89 [==============================] - 15s 169ms/step - loss: 3.3211 - acc: 0.1221 - val_loss: 2.5631 - val_acc: 0.1638\n",
            "Epoch 162/250\n",
            "89/89 [==============================] - 16s 178ms/step - loss: 3.2039 - acc: 0.1498 - val_loss: 2.5562 - val_acc: 0.1681\n",
            "Epoch 163/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.3052 - acc: 0.1377 - val_loss: 2.5670 - val_acc: 0.1616\n",
            "Epoch 164/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 3.2939 - acc: 0.1498 - val_loss: 2.5423 - val_acc: 0.1746\n",
            "Epoch 165/250\n",
            "89/89 [==============================] - 15s 166ms/step - loss: 3.2532 - acc: 0.1363 - val_loss: 2.5510 - val_acc: 0.1595\n",
            "Epoch 166/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 3.2607 - acc: 0.1377 - val_loss: 2.5495 - val_acc: 0.1616\n",
            "Epoch 167/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.2719 - acc: 0.1384 - val_loss: 2.5449 - val_acc: 0.1703\n",
            "Epoch 168/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.1929 - acc: 0.1334 - val_loss: 2.5541 - val_acc: 0.1746\n",
            "Epoch 169/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.2364 - acc: 0.1235 - val_loss: 2.5302 - val_acc: 0.1853\n",
            "Epoch 170/250\n",
            "89/89 [==============================] - 15s 164ms/step - loss: 3.1933 - acc: 0.1377 - val_loss: 2.5292 - val_acc: 0.1832\n",
            "Epoch 171/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.2652 - acc: 0.1363 - val_loss: 2.5505 - val_acc: 0.1616\n",
            "Epoch 172/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.2474 - acc: 0.1341 - val_loss: 2.5308 - val_acc: 0.1832\n",
            "Epoch 173/250\n",
            "89/89 [==============================] - 16s 178ms/step - loss: 3.2090 - acc: 0.1377 - val_loss: 2.5481 - val_acc: 0.1638\n",
            "Epoch 174/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.2568 - acc: 0.1313 - val_loss: 2.5301 - val_acc: 0.1703\n",
            "Epoch 175/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.1912 - acc: 0.1363 - val_loss: 2.5287 - val_acc: 0.1832\n",
            "Epoch 176/250\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 3.2319 - acc: 0.1455 - val_loss: 2.5255 - val_acc: 0.1875\n",
            "Epoch 177/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.2464 - acc: 0.1341 - val_loss: 2.5409 - val_acc: 0.1810\n",
            "Epoch 178/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.1396 - acc: 0.1498 - val_loss: 2.5403 - val_acc: 0.1853\n",
            "Epoch 179/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 3.2779 - acc: 0.1348 - val_loss: 2.5248 - val_acc: 0.1767\n",
            "Epoch 180/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.1767 - acc: 0.1434 - val_loss: 2.5534 - val_acc: 0.1875\n",
            "Epoch 181/250\n",
            "89/89 [==============================] - 11s 116ms/step - loss: 3.2037 - acc: 0.1270 - val_loss: 2.5271 - val_acc: 0.1767\n",
            "Epoch 182/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.2495 - acc: 0.1462 - val_loss: 2.5394 - val_acc: 0.1789\n",
            "Epoch 183/250\n",
            "89/89 [==============================] - 15s 168ms/step - loss: 3.1041 - acc: 0.1554 - val_loss: 2.5399 - val_acc: 0.1767\n",
            "Epoch 184/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.1487 - acc: 0.1405 - val_loss: 2.5498 - val_acc: 0.1724\n",
            "Epoch 185/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.1818 - acc: 0.1327 - val_loss: 2.5325 - val_acc: 0.1875\n",
            "Epoch 186/250\n",
            "89/89 [==============================] - 13s 146ms/step - loss: 3.1081 - acc: 0.1519 - val_loss: 2.5259 - val_acc: 0.1853\n",
            "Epoch 187/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 3.1284 - acc: 0.1547 - val_loss: 2.5256 - val_acc: 0.1703\n",
            "Epoch 188/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.1408 - acc: 0.1490 - val_loss: 2.5304 - val_acc: 0.1810\n",
            "Epoch 189/250\n",
            "89/89 [==============================] - 15s 169ms/step - loss: 3.1871 - acc: 0.1419 - val_loss: 2.5418 - val_acc: 0.1724\n",
            "Epoch 190/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.1436 - acc: 0.1441 - val_loss: 2.5240 - val_acc: 0.1810\n",
            "Epoch 191/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 3.1687 - acc: 0.1377 - val_loss: 2.5141 - val_acc: 0.1940\n",
            "Epoch 192/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.1164 - acc: 0.1341 - val_loss: 2.5126 - val_acc: 0.1961\n",
            "Epoch 193/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.2090 - acc: 0.1235 - val_loss: 2.5139 - val_acc: 0.1810\n",
            "Epoch 194/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.1607 - acc: 0.1483 - val_loss: 2.5304 - val_acc: 0.1767\n",
            "Epoch 195/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 3.1747 - acc: 0.1434 - val_loss: 2.5271 - val_acc: 0.1789\n",
            "Epoch 196/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.1543 - acc: 0.1533 - val_loss: 2.5135 - val_acc: 0.1767\n",
            "Epoch 197/250\n",
            "89/89 [==============================] - 16s 178ms/step - loss: 3.2068 - acc: 0.1299 - val_loss: 2.5273 - val_acc: 0.1832\n",
            "Epoch 198/250\n",
            "89/89 [==============================] - 15s 167ms/step - loss: 3.1436 - acc: 0.1490 - val_loss: 2.5326 - val_acc: 0.1767\n",
            "Epoch 199/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 3.2188 - acc: 0.1377 - val_loss: 2.5106 - val_acc: 0.1853\n",
            "Epoch 200/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.1225 - acc: 0.1469 - val_loss: 2.5293 - val_acc: 0.1875\n",
            "Epoch 201/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.1806 - acc: 0.1476 - val_loss: 2.5185 - val_acc: 0.1746\n",
            "Epoch 202/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.1924 - acc: 0.1313 - val_loss: 2.5282 - val_acc: 0.1789\n",
            "Epoch 203/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.1170 - acc: 0.1512 - val_loss: 2.5307 - val_acc: 0.1724\n",
            "Epoch 204/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.1209 - acc: 0.1320 - val_loss: 2.5299 - val_acc: 0.1810\n",
            "Epoch 205/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.1482 - acc: 0.1412 - val_loss: 2.5288 - val_acc: 0.1789\n",
            "Epoch 206/250\n",
            "89/89 [==============================] - 15s 168ms/step - loss: 3.1026 - acc: 0.1625 - val_loss: 2.5098 - val_acc: 0.1875\n",
            "Epoch 207/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.1793 - acc: 0.1320 - val_loss: 2.5003 - val_acc: 0.1875\n",
            "Epoch 208/250\n",
            "89/89 [==============================] - 16s 179ms/step - loss: 3.1196 - acc: 0.1512 - val_loss: 2.5070 - val_acc: 0.1940\n",
            "Epoch 209/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.1700 - acc: 0.1398 - val_loss: 2.5192 - val_acc: 0.1810\n",
            "Epoch 210/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.1267 - acc: 0.1441 - val_loss: 2.5280 - val_acc: 0.1832\n",
            "Epoch 211/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.1283 - acc: 0.1512 - val_loss: 2.5181 - val_acc: 0.1810\n",
            "Epoch 212/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.0994 - acc: 0.1356 - val_loss: 2.5218 - val_acc: 0.1810\n",
            "Epoch 213/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.1098 - acc: 0.1476 - val_loss: 2.5165 - val_acc: 0.1832\n",
            "Epoch 214/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.0463 - acc: 0.1540 - val_loss: 2.5224 - val_acc: 0.1875\n",
            "Epoch 215/250\n",
            "89/89 [==============================] - 15s 166ms/step - loss: 3.1189 - acc: 0.1377 - val_loss: 2.5002 - val_acc: 0.1940\n",
            "Epoch 216/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.0869 - acc: 0.1746 - val_loss: 2.5110 - val_acc: 0.1832\n",
            "Epoch 217/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.0573 - acc: 0.1320 - val_loss: 2.5255 - val_acc: 0.1767\n",
            "Epoch 218/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.1290 - acc: 0.1490 - val_loss: 2.5245 - val_acc: 0.1897\n",
            "Epoch 219/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.1301 - acc: 0.1384 - val_loss: 2.5089 - val_acc: 0.1897\n",
            "Epoch 220/250\n",
            "89/89 [==============================] - 13s 137ms/step - loss: 3.1077 - acc: 0.1398 - val_loss: 2.5015 - val_acc: 0.1789\n",
            "Epoch 221/250\n",
            "89/89 [==============================] - 13s 139ms/step - loss: 3.1198 - acc: 0.1327 - val_loss: 2.5228 - val_acc: 0.1767\n",
            "Epoch 222/250\n",
            "89/89 [==============================] - 15s 169ms/step - loss: 3.0990 - acc: 0.1441 - val_loss: 2.5196 - val_acc: 0.1789\n",
            "Epoch 223/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.1345 - acc: 0.1377 - val_loss: 2.5023 - val_acc: 0.1853\n",
            "Epoch 224/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 3.1513 - acc: 0.1426 - val_loss: 2.5142 - val_acc: 0.1832\n",
            "Epoch 225/250\n",
            "89/89 [==============================] - 13s 146ms/step - loss: 3.0995 - acc: 0.1618 - val_loss: 2.5136 - val_acc: 0.1897\n",
            "Epoch 226/250\n",
            "89/89 [==============================] - 16s 179ms/step - loss: 3.1208 - acc: 0.1490 - val_loss: 2.5079 - val_acc: 0.1832\n",
            "Epoch 227/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.1798 - acc: 0.1419 - val_loss: 2.5169 - val_acc: 0.1875\n",
            "Epoch 228/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.0349 - acc: 0.1554 - val_loss: 2.5073 - val_acc: 0.1789\n",
            "Epoch 229/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.1178 - acc: 0.1419 - val_loss: 2.5212 - val_acc: 0.1853\n",
            "Epoch 230/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.0685 - acc: 0.1547 - val_loss: 2.4897 - val_acc: 0.1853\n",
            "Epoch 231/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.0734 - acc: 0.1377 - val_loss: 2.5166 - val_acc: 0.1810\n",
            "Epoch 232/250\n",
            "89/89 [==============================] - 15s 166ms/step - loss: 3.0152 - acc: 0.1462 - val_loss: 2.5319 - val_acc: 0.1832\n",
            "Epoch 233/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.0537 - acc: 0.1412 - val_loss: 2.5134 - val_acc: 0.1918\n",
            "Epoch 234/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.0521 - acc: 0.1398 - val_loss: 2.5067 - val_acc: 0.1875\n",
            "Epoch 235/250\n",
            "89/89 [==============================] - 16s 178ms/step - loss: 3.0169 - acc: 0.1533 - val_loss: 2.4992 - val_acc: 0.1853\n",
            "Epoch 236/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.9387 - acc: 0.1639 - val_loss: 2.5168 - val_acc: 0.1810\n",
            "Epoch 237/250\n",
            "89/89 [==============================] - 16s 168ms/step - loss: 3.1479 - acc: 0.1476 - val_loss: 2.5107 - val_acc: 0.1875\n",
            "Epoch 238/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.0303 - acc: 0.1505 - val_loss: 2.5127 - val_acc: 0.1897\n",
            "Epoch 239/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.0696 - acc: 0.1554 - val_loss: 2.5101 - val_acc: 0.1789\n",
            "Epoch 240/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.0504 - acc: 0.1604 - val_loss: 2.5176 - val_acc: 0.1724\n",
            "Epoch 241/250\n",
            "89/89 [==============================] - 12s 126ms/step - loss: 3.0699 - acc: 0.1490 - val_loss: 2.5102 - val_acc: 0.1918\n",
            "Epoch 242/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.0931 - acc: 0.1441 - val_loss: 2.4960 - val_acc: 0.1832\n",
            "Epoch 243/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.0554 - acc: 0.1391 - val_loss: 2.5072 - val_acc: 0.1875\n",
            "Epoch 244/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.0110 - acc: 0.1462 - val_loss: 2.5001 - val_acc: 0.1789\n",
            "Epoch 245/250\n",
            "89/89 [==============================] - 11s 114ms/step - loss: 3.0777 - acc: 0.1483 - val_loss: 2.5105 - val_acc: 0.1724\n",
            "Epoch 246/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.0946 - acc: 0.1462 - val_loss: 2.5086 - val_acc: 0.1703\n",
            "Epoch 247/250\n",
            "89/89 [==============================] - 15s 166ms/step - loss: 3.0309 - acc: 0.1483 - val_loss: 2.4900 - val_acc: 0.1767\n",
            "Epoch 248/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.0425 - acc: 0.1412 - val_loss: 2.5023 - val_acc: 0.1918\n",
            "Epoch 249/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.0351 - acc: 0.1533 - val_loss: 2.4830 - val_acc: 0.1940\n",
            "Epoch 250/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.0423 - acc: 0.1476 - val_loss: 2.4952 - val_acc: 0.1875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'co', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "d53156ba-9a81-4915-8c97-2ef25816d1d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAA6vklEQVR4nO3de3yT5fn48c/VtBRoORYoWihQJ1CRYzmIHEQFB4goioJWsKJDGCpzOqbilOn4+t3k60+ZMoZnEIeKyhR0AkMElE0OMkAKiJyEasEiJ4HSw/X7I0mXliRN27Rp0uv9evEiefLkyf0kcOXO9dz3dYuqYowxJvxFhboBxhhjgsMCujHGRAgL6MYYEyEsoBtjTISwgG6MMRHCAroxxkQIC+jGKxH5SERuC/a+oSQie0VkYCUcV0XkZ67bs0Xkd4HsW47XSReRpeVtp5/jDhCRA8E+rql60aFugAkeETnpcbcukAsUuO7fparzAz2Wqg6pjH0jnapOCMZxRKQ1sAeIUdV817HnAwF/hqbmsYAeQVQ13n1bRPYCd6rq8pL7iUi0O0gYYyKHpVxqAPdPahH5rYh8D7wiIo1EZLGIHBaRH123W3g8Z6WI3Om6nSEia0RkhmvfPSIypJz7thGRVSJyQkSWi8jzIvK6j3YH0sYnROQz1/GWikgTj8fHiMg+EckRkal+3p9eIvK9iDg8to0Qkc2u2z1FZK2IHBWR70TkORGp5eNYr4rIHzzu/8b1nCwRGVdi36tF5EsROS4i34rINI+HV7n+PioiJ0Wkt/u99Xj+pSKyTkSOuf6+NND3xh8RSXU9/6iIfCUiwz0eGyoi21zHPCgiD7i2N3F9PkdF5IiIrBYRiy9VzN7wmqM50BhoBYzH+dm/4rqfDJwGnvPz/F7ADqAJ8CfgJRGRcuz7BvAFkABMA8b4ec1A2ngLcDvQDKgFuAPMRcBfXMc/3/V6LfBCVf8N/ARcUeK4b7huFwD3uc6nN3Al8Es/7cbVhsGu9gwCLgRK5u9/AsYCDYGrgYkicp3rsf6uvxuqaryqri1x7MbAEmCm69yeBpaISEKJczjnvSmlzTHAB8BS1/PuAeaLSDvXLi/hTN/VAy4GVri23w8cAJoCicDDgNUVqWIW0GuOQuAxVc1V1dOqmqOq76jqKVU9AUwHLvPz/H2q+oKqFgCvAefh/I8b8L4ikgz0AB5V1bOqugZ439cLBtjGV1R1p6qeBt4Curi2jwQWq+oqVc0Ffud6D3z5G3AzgIjUA4a6tqGqG1T1X6qar6p7gb96aYc3N7nat1VVf8L5BeZ5fitVdYuqFqrqZtfrBXJccH4BfK2q81zt+huwHbjGYx9f740/lwDxwP+6PqMVwGJc7w2QB1wkIvVV9UdV3eix/TyglarmqepqtUJRVc4Ces1xWFXPuO+ISF0R+asrJXEc50/8hp5phxK+d99Q1VOum/Fl3Pd84IjHNoBvfTU4wDZ+73H7lEebzvc8tiug5vh6LZy98etFJBa4Htioqvtc7WjrSid872rH/+DsrZemWBuAfSXOr5eIfOJKKR0DJgR4XPex95XYtg9I8rjv670ptc2q6vnl53ncG3B+2e0TkU9FpLdr+1PALmCpiOwWkQcDOw0TTBbQa46SvaX7gXZAL1Wtz39/4vtKowTDd0BjEanrsa2ln/0r0sbvPI/tes0EXzur6jacgWsIxdMt4EzdbAcudLXj4fK0AWfayNMbOH+htFTVBsBsj+OW1rvNwpmK8pQMHAygXaUdt2WJ/HfRcVV1napeizMdswhnzx9VPaGq96tqCjAc+LWIXFnBtpgysoBec9XDmZM+6srHPlbZL+jq8a4HpolILVfv7ho/T6lIGxcCw0Skr+sC5uOU/u/9DWAyzi+Ot0u04zhwUkTaAxMDbMNbQIaIXOT6QinZ/no4f7GcEZGeOL9I3A7jTBGl+Dj2h0BbEblFRKJFZBRwEc70SEX8G2dvfoqIxIjIAJyf0QLXZ5YuIg1UNQ/ne1IIICLDRORnrmslx3Bed/CX4jKVwAJ6zfUMUAf4AfgX8I8qet10nBcWc4A/AG/iHC/vzTOUs42q+hUwCWeQ/g74EedFO3/cOewVqvqDx/YHcAbbE8ALrjYH0oaPXOewAmc6YkWJXX4JPC4iJ4BHcfV2Xc89hfOawWeukSOXlDh2DjAM56+YHGAKMKxEu8tMVc/iDOBDcL7vs4CxqrrdtcsYYK8r9TQB5+cJzou+y4GTwFpglqp+UpG2mLITu25hQklE3gS2q2ql/0IwJtJZD91UKRHpISIXiEiUa1jftThzscaYCrKZoqaqNQfexXmB8gAwUVW/DG2TjIkMlnIxxpgIYSkXY4yJECFLuTRp0kRbt24dqpc3xpiwtGHDhh9Utam3x0IW0Fu3bs369etD9fLGGBOWRKTkDOEilnIxxpgIYQHdGGMihAV0Y4yJEDYO3ZgaJC8vjwMHDnDmzJnSdzYhVbt2bVq0aEFMTEzAz7GAbkwNcuDAAerVq0fr1q3xvT6JCTVVJScnhwMHDtCmTZuAnxdWKZf52dm0XruWqJUrab12LfOzs0PdJGPCypkzZ0hISLBgXs2JCAkJCWX+JRU2PfT52dmM37GDU4XOipz7cnMZv2MHAOmJvhbOMcaUZME8PJTncwqbHvrU3buLgrnbqcJCpu7eHaIWGWNM9RI2AX1/rveS2b62G2Oqn5ycHLp06UKXLl1o3rw5SUlJRffPnj3r97nr16/n3nvvLfU1Lr300qC0deXKlQwbNiwox6oqYZNySY6NZZ+X4J0cGxuC1hhTM8zPzmbq7t3sz80lOTaW6SkpFUpxJiQksGnTJgCmTZtGfHw8DzzwQNHj+fn5REd7D0vdu3ene/fupb7G559/Xu72hbuw6aFPT0mhblTx5taNimJ6iq8VuowxFeG+brUvNxflv9etgj0YISMjgwkTJtCrVy+mTJnCF198Qe/evenatSuXXnopO1zXyjx7zNOmTWPcuHEMGDCAlJQUZs6cWXS8+Pj4ov0HDBjAyJEjad++Penp6biry3744Ye0b9+etLQ07r333lJ74keOHOG6666jU6dOXHLJJWzevBmATz/9tOgXRteuXTlx4gTfffcd/fv3p0uXLlx88cWsXr06qO+XP2HTQ3f3CoLZWzDG+ObvulWw/98dOHCAzz//HIfDwfHjx1m9ejXR0dEsX76chx9+mHfeeeec52zfvp1PPvmEEydO0K5dOyZOnHjOmO0vv/ySr776ivPPP58+ffrw2Wef0b17d+666y5WrVpFmzZtuPnmm0tt32OPPUbXrl1ZtGgRK1asYOzYsWzatIkZM2bw/PPP06dPH06ePEnt2rWZM2cOP//5z5k6dSoFBQWcOnUqaO9TacImoIMzqFsAN6ZqVOV1qxtvvBGHwwHAsWPHuO222/j6668REfLy8rw+5+qrryY2NpbY2FiaNWtGdnY2LVq0KLZPz549i7Z16dKFvXv3Eh8fT0pKStH47ptvvpk5c+b4bd+aNWuKvlSuuOIKcnJyOH78OH369OHXv/416enpXH/99bRo0YIePXowbtw48vLyuO666+jSpUtF3poyCZuUizGmavm6PlUZ163i4uKKbv/ud7/j8ssvZ+vWrXzwwQc+x2LHerTD4XCQn59frn0q4sEHH+TFF1/k9OnT9OnTh+3bt9O/f39WrVpFUlISGRkZzJ07N6iv6Y8FdGOMV6G6bnXs2DGSkpIAePXVV4N+/Hbt2rF792727t0LwJtvvlnqc/r168f8+fMBZ26+SZMm1K9fn2+++YaOHTvy29/+lh49erB9+3b27dtHYmIiv/jFL7jzzjvZuHFj0M/Bl4ACuojsFZEtIrJJRM4pYi4iA0TkmOvxTSLyaPCbaoypSumJicxp145WsbEI0Co2ljnt2lV62nPKlCk89NBDdO3aNeg9aoA6deowa9YsBg8eTFpaGvXq1aNBgwZ+nzNt2jQ2bNhAp06dePDBB3nttdcAeOaZZ7j44ovp1KkTMTExDBkyhJUrV9K5c2e6du3Km2++yeTJk4N+Dr4EtKaoiOwFuqvqDz4eHwA8oKoBD9rs3r272gIXxlStzMxMUlNTQ92MkDt58iTx8fGoKpMmTeLCCy/kvvvuC3WzzuHt8xKRDarqdfympVyMMTXOCy+8QJcuXejQoQPHjh3jrrvuCnWTgiLQUS4KLBURBf6qqt4uCfcWkf8AWTh7618Fq5HGGBNM9913X7XskVdUoAG9r6oeFJFmwDIR2a6qqzwe3wi0UtWTIjIUWARcWPIgIjIeGA+QnJxcsZYbY4wpJqCUi6oedP19CHgP6Fni8eOqetJ1+0MgRkSaeDnOHFXtrqrdmzb1umi1McaYcio1oItInIjUc98GrgK2ltinubhqPYpIT9dxc4LfXGOMMb4EknJJBN5zxeto4A1V/YeITABQ1dnASGCiiOQDp4HRGsjwGWOMMUFTag9dVXeramfXnw6qOt21fbYrmKOqz7ke66yql6hqzS13Zozx6fLLL+fjjz8utu2ZZ55h4sSJPp8zYMAA3EOchw4dytGjR8/ZZ9q0acyYMcPvay9atIht27YV3X/00UdZvnx5GVrvXXUqs2vDFo0xVebmm29mwYIFxbYtWLAgoAJZ4KyS2LBhw3K9dsmA/vjjjzNw4MByHau6soBujKkyI0eOZMmSJUWLWezdu5esrCz69evHxIkT6d69Ox06dOCxxx7z+vzWrVvzww/O+Y3Tp0+nbdu29O3bt6jELjjHmPfo0YPOnTtzww03cOrUKT7//HPef/99fvOb39ClSxe++eYbMjIyWLhwIQD//Oc/6dq1Kx07dmTcuHHkugqQtW7dmscee4xu3brRsWNHtm/f7vf8Ql1mN6yqLRpjgudXv/pV0WITwdKlSxeeeeYZn483btyYnj178tFHH3HttdeyYMECbrrpJkSE6dOn07hxYwoKCrjyyivZvHkznTp18nqcDRs2sGDBAjZt2kR+fj7dunUjLS0NgOuvv55f/OIXADzyyCO89NJL3HPPPQwfPpxhw4YxcuTIYsc6c+YMGRkZ/POf/6Rt27aMHTuWv/zlL/zqV78CoEmTJmzcuJFZs2YxY8YMXnzxRZ/nF+oyu9ZDN8ZUKc+0i2e65a233qJbt2507dqVr776qlh6pKTVq1czYsQI6tatS/369Rk+fHjRY1u3bqVfv3507NiR+fPn89VX/uc47tixgzZt2tC2bVsAbrvtNlat+u80m+uvvx6AtLS0ooJevqxZs4YxY8YA3svszpw5k6NHjxIdHU2PHj145ZVXmDZtGlu2bKFevXp+jx0I66EbU0P560lXpmuvvZb77ruPjRs3curUKdLS0tizZw8zZsxg3bp1NGrUiIyMDJ9lc0uTkZHBokWL6Ny5M6+++iorV66sUHvdJXgrUn73wQcf5Oqrr+bDDz+kT58+fPzxx0VldpcsWUJGRga//vWvGTt2bIXaaj10Y0yVio+P5/LLL2fcuHFFvfPjx48TFxdHgwYNyM7O5qOPPvJ7jP79+7No0SJOnz7NiRMn+OCDD4oeO3HiBOeddx55eXlFJW8B6tWrx4kTJ845Vrt27di7dy+7du0CYN68eVx22WXlOrdQl9m1HroxpsrdfPPNjBgxoij14i432759e1q2bEmfPn38Pr9bt26MGjWKzp0706xZM3r06FH02BNPPEGvXr1o2rQpvXr1Kgrio0eP5he/+AUzZ84suhgKULt2bV555RVuvPFG8vPz6dGjBxMmTCjXebnXOu3UqRN169YtVmb3k08+ISoqig4dOjBkyBAWLFjAU089RUxMDPHx8UFZCCOg8rmVoSLlc4O9ErkxNYWVzw0vZS2fG3Y9dPdK5O7Fa90rkQMW1I0xNVrY5dD9rURujDE1WdgF9KpcidyYSGRllsJDeT6nsAvoVbkSuTGRpnbt2uTk5FhQr+ZUlZycHGrXrl2m54VdDn16SkqxHDpUzUrkxkSCFi1acODAAQ4fPhzqpphS1K5dmxYtWpTpOWEX0N0XPm2UizFlFxMTQ5s2bULdDFNJwi6ggzOoWwA3xpjiwi6HbowxxjsL6MYYEyEsoBtjTISwgG6MMRHCAroxxkQIC+jGGBMhLKAbY0yECCigi8heEdkiIptE5Jyat+I0U0R2ichmEekW/KYaY4zxpywTiy5X1R98PDYEuND1pxfwF9ffxhhjqkiwUi7XAnPV6V9AQxE5L0jHNsYYE4BAA7oCS0Vkg4iM9/J4EvCtx/0Drm3GGGOqSKApl76qelBEmgHLRGS7qq4q64u5vgzGAyQnJ5f16cYYY/wIqIeuqgddfx8C3gN6ltjlINDS434L17aSx5mjqt1VtXvTpk3L12JjjDFelRrQRSROROq5bwNXAVtL7PY+MNY12uUS4Jiqfhf01hpjjPEpkJRLIvCeiLj3f0NV/yEiEwBUdTbwITAU2AWcAm6vnOYaY4zxpdSArqq7gc5ets/2uK3ApOA2zRhjTFnYTFFjjIkQYRvQ52dn03rtWqJWrqT12rXMz84OdZOMMSakwnIJuvnZ2cUWit6Xm8v4HTsAbGk6Y0yNFZY99Km7dxcFc7dThYVM3b07RC0yxpjQC8uAvj83t0zbjTGmJgjLgJ4cG+t1exRYLt0YU2OFZUCfnpJC3ahzm14AjN+xw4K6MaZGCsuAnp6YyJx27XB4ecxy6caYmiosAzo4g3qhj8csl26MqYnCNqADNI72PurSV47dGGMiWdgG9PnZ2RzPz/f62L7cXJtsZIypccI2oE/dvZs8P4+7JxtZUDfG1BRhG9ADyZPbBVJjTE0StgE90Dy5XSA1xtQUYRvQfY1FL8kukBpjaoqwDejuseitYmMRIMHhoJZzEY4idaOimJ6SEpoGGmNMFQvLaotu6YmJxaorzs/OZuru3ezPzSU5NpbpKSlWfdEYU2OEbQ/dm/TERPb27s281FQAxmRm2vBFY0yNEdY9dG+sVroxpqaKmB66ewWjWzMzrVa6MaZGiogeesleuTf7bPiiMSbCRUQP3dsKRiUJVivdGBPZIiKgBzJ5SMHSLsaYiBZwQBcRh4h8KSKLvTyWISKHRWST68+dwW2mfzZr1BhjytZDnwxk+nn8TVXt4vrzYgXbVSY2a9QYYwIM6CLSArgaqNJAHSj3rNEEh7c1jJxs1qgxJtIF2kN/BpgCPhcJArhBRDaLyEIRaeltBxEZLyLrRWT94cOHy9hU/9ITE4n3seCFA7iteXOm7t5N1MqVNtnIGBORSg3oIjIMOKSqG/zs9gHQWlU7AcuA17ztpKpzVLW7qnZv2rRpuRrsj68ceQHw2vffsy83F8VqpRtjIlMgPfQ+wHAR2QssAK4Qkdc9d1DVHFV1R9MXgbSgtjJAvnLkDrDJRsaYiFdqQFfVh1S1haq2BkYDK1T1Vs99ROQ8j7vD8X/xtNJ4uzhaNyqKAh/726gXY0wkKfc4dBF5XESGu+7eKyJfich/gHuBjGA0rqxKltRtFRtbdN8bG/VijIkkoqoheeHu3bvr+vXrK/115mdnM3nnTnIKivfT60ZFMaddOyvYZYwJKyKyQVW7e3ssImq5+OKrxktCdDTPXnihBXNjTESJiKn/vvis8aJqwdwYE3Eiuofu66JnTkFB0ZBFW+HIGBMpIjqgJ8fG+iybe2tm8YE4thCGMSbcRXTKpaxT/W1sujEmnEV0QE9PTCTBRzkAX2xsujEmXEV0QAd49sILA6rE6GZj040x4SriA7p7spHvOozFnfS4YGqMMeEk4gM6OIP6a6mpAfXUc/LzrXCXMSYs1YiADmXrqdvFUWNMOKoxAR2cQd3/UtL/tS8313rpxpiwUqMCOpTtoqelXowx4aTGBfRA1x8FS70YY8JLRM8U9cY9C3Tq7t0+Z5F62pebS5PVq4uqNVphL2NMdVXjeujgDOp7e/fm9UBHvniU3s3Jz2fc9u2WijHGVDs1MqC7eS6IASABPu+sKrdmZtpi08aYaqVGB3T4b29dBwxgXmpqmYK7LTZtjKlOanxA95SemMj0lBSigEDXcbILp8aY6sICuof52dncnpkZ8Fh1NyvoZYypDiyge5i6ezd55XieFfQyxlQHFtA9lLenXbKg1/zsbFqvXUvUypV24dQYU2Vq3Dh0f/ytcORPTn4+YzIzuTUzkwSHgxOFhZxVZxbeVkIyxlSVgHvoIuIQkS9FZLGXx2JF5E0R2SUi/xaR1kFtZRWZnpJCjJftDqCW+B/34r6ImlNQUBTM3ezCqTGmKpQl5TIZyPTx2B3Aj6r6M+D/AX+saMNCIT0xkVdSU0lw/LcmY0J0NK+lpvJy+/a0io0NeKx6SXbh1BhT2QJKuYhIC+BqYDrway+7XAtMc91eCDwnIqKqgY7+qzbSExP9pkYCLRlQkl04NcZUtkB76M8AU8DniL4k4FsAVc0HjgEJJXcSkfEisl5E1h8+fLjsrQU+++wzRowYQVZWVrmeX17zs7MZv2NHuYK5AEMTznk7jDEmqEoN6CIyDDikqhsq+mKqOkdVu6tq96ZNm5brGIcPH2bRokVkV/HIkam7d3OqsKwj1J0UmJ2VhdioF2NMJQqkh94HGC4ie4EFwBUi8nqJfQ4CLQFEJBpoAOQEsZ1FGjZsCMDRo0cr4/A+VTQH7s49WbkAY0xlKTWgq+pDqtpCVVsDo4EVqnprid3eB25z3R7p2qdS8ucNGjQA4NixY5VxeJ+CmQM/VVjI5J07abJ6NbJyJbJyJU3WrLEgb4ypkHJPLBKRx0VkuOvuS0CCiOzCedH0wWA0zptQBfSyLIwRiJyCAivLa4wJqjJFKFVdqarDXLcfVdX3XbfPqOqNqvozVe2pqpU26DpUAd2z1K5AUVXGYDqr6ne8us1ANcb4E3YzRevXrw9UfUCHc4c0tl67tlyjXvzxlat3j7JxX5i1GajGmJLCLqDHxMQQFxdX5RdFvZmeklIsyALEAPWjo8nJzy/XMRs7HLReu5b9ubk0djhAhCP5+UQBBSX2dc9AtYBujIEwLc7VoEGDkPTQS/KWhnklNZUf+vYtV0rGAZwoLGRfbi6KK8+en49ybjB3sxmoxhi3sOuhQ/UJ6OB7Zqm33ntpCoCCMg4Oshmoxhg366FXkpLrlVaGWiJMT0mptOMbY8JLWAb0hg0bVoscemnc65WWt6BXaeq5hlF6G/liI2KMqXnCNuWyO4zK0Za3znppcgoKGJOZec4s1M+OHeO177+3ETHG1DBh2UMPh5SLp2BPSvJUMuN+qrCQv2ZlnZO7t5rsxkS+sO2hh1NAd/eKJ+/cWWx2aGXxdRl2X24uTdas4Uh+PsmxsUxPSbEeuzERJGwD+pkzZ8jNzSU2TEZ5uEfDzM/OZuru3ezPza20VIw/7vHxnmkYoFibLNAbE57CMqC7Ky4eO3aMZs2ahbYxZRTobFOheDql5P1gcBcJO61q+XZjIkDY5tAhNNP/g81bfr1uVBQTzj+/2ISleamplTJaJqegIOB8u3vkjKxcSbS7SuTq1TRZs8ZG0xhTDYRlDz2SArq7FxxIyqO8y9+VR8kZqCVrybivBHheE7DevTGhZQG9GihtHVO36Skp3J6ZSV4VtCk5NrZYvt9bLRlvrL6MMaETlgHdM4dek3gbLROF71EtFfFdbi63ZmYW3S/L2Jx9ublFBcbsIqsxVSesA/qPP/4Y2oaEQMne/Pzs7GKBN1jOVvD57tSQpWGMqTpheVE0MTEREeHgwYOhbkrIpScmkhBdvb+XbVKTMVUjLAN6bGwsiYmJ7N+/P9RNqRaevfDCc0bKxOAs3lXZ4kQC+kdkZX6NqXxhGdABkpOT+fbbb0PdjGrBV132l9u3L7bt9dRUXk9NDWoFSBUJKIfvvshqBcOMqTyiZay/HSzdu3fX9evXl/v5N954I1u3biWzEvLHNcUvd+5kdlZWhScsOfB/0dQ9Kark5Ki6UVHMadcOsJmqxgRKRDaoandvj4VtD71ly5bs37+fUH0hRYJZbdsyLzUVRwWPU8C56R3x+Nv9CXkrJDYmM5Nx27cXrdK0zzW6RkrpxVtv35hzVe+raX4kJydz6tQpjhw5QkJCQqibE7bSExMZE4RfOapKnAg/ub5g64pwWrXUdIwCZ318KXuWA/4wJ6eoBz80IcFneWCw3r6puUoN6CJSG1gFxLr2X6iqj5XYJwN4CnAPO3lOVV8MblOLS05OBuDbb7+1gF5BwSgSlgfkewTmn4L0y+lUYSF/ycoqur8vN9drmsjq0hgTWMolF7hCVTsDXYDBInKJl/3eVNUurj+VGszBmXIBbKRLEASrXntVJb98vU5Z6tIYE4lK/V+sTiddd2Ncf0KeuHb30C2gV1zJ9U9LG+xY0Zx7VduXm1tqTt6YSBBQt0xEHCKyCTgELFPVf3vZ7QYR2SwiC0WkpY/jjBeR9SKy/vDhw+VvNdC0aVNiY2Nt6GKQuNc/1QEDmOcxtLFkcK8bFcX488+vtBWYKpM7BVOeC62BXIS1C7Um1Mo0bFFEGgLvAfeo6laP7QnASVXNFZG7gFGqeoW/Y1V02CLAxRdfTKtWrViyZEmFjmN8K7kgh/sio3t7VS/QEQwO4LXU1HNKKHhWk4Tiwyp9PeY+hr/nW/7eBJO/YYtlHocuIo8Cp1R1ho/HHcARVW3g7zjBCOjjx4/n7bffJicnh6gw7DFGAl8LdJRFQnQ0NzVrVmzkSrmP5XAEtMyfZ7Cdn53NbZmZXsfSJzgcxEdHez3HVrGx7O3dG/D9PnjuY0wwVGgcuog0dfXMEZE6wCBge4l9zvO4Oxyoktk+ffr04ejRoza5KIR8LdDhnpXqL9/eKjaWieefT7zDweysLOqIkBAdXTSzdaLHIh+B5u0DXbP1VGEht2Zm0mT1asZt3+5zYlROQYHPLyzPcga+ShtYyQNTlQLp1p4HfCIim4F1OHPoi0XkcREZ7trnXhH5SkT+A9wLZFROc4vr06cPAJ999llVvJzxwlvZAXfPNz0x0ec4dMH5ZfDa998XTSrKKSjgdGEh81JT2du7N7PatmV6SgrJsbFlKt9bFjkFBT7HwZcm2aOEQrKPcgqNHY6g5dUtR29KE7ZT/8E5maV58+YMHjyY1157LUgtM8HkLxUB+E1TeMtLVxd1o6K4rXnzoglPjR0OThQWFvtyiAFEpNi2ks8LdPKT5eiNW0RO/Qfnf5b+/fvz8ccfc+bMmVA3x3jhKyUzPSXFb5rCndeujsHcAdzWvPk5vy48A3cUzslWJXv/7olSnqUO/I28cZu6e7fXMfa3ZmZab90UCeuADjBx4kSys7OZN29eqJtivPCXkvGXphi/Y0dQ0iyVUUC4APgwJ8fvl01Zvobcs1z9pVP85eID/VIwkS+sUy7gTLv07NmTo0ePsmPHDhvtEkZ8pRHqREWRk59f4ePXEuHl9u2Bql1gOxhKplMCGU2U4HDwQ79+VdE8E0IRm3IBZ9rlV7/6Fbt27WLt2rWhbo4pA1+99yN+gnmgC3fEOxy83L590cXZvb17V0pvvbKUTKcEUp4hp6CAJmvWWE+9Bgv7gA5wzTXXUKtWLd55551QN8WUkTvYFg4YwN7evf2mYhzgdeEOz+GN7oU8TvTrd87FQl/H9aa6BH/PipN1Avgiy8nPdw7HtMBeI4V9ysXtmmuuYcuWLezZswepgqXXTOWprBEdgYyaESg28iQYE6dCxV2LvpXrfCCw0sK+Zgeb6iGoM0WDJdgB/dVXX+X2229nyZIlDB06NGjHNaFRWUHF36xQb7M6yzJ0suSKTNWJtyGU4ExN/VRQUPQew7llDmKA+tHRHMnPtwBfDdSIgH7y5EkuueQS9u/fz+rVq+ncuXPQjm0iS1l/AXh+udT1WMTDk7cLsNU5wFeEjX8PrYi+KOoWHx/Pxx9/jMPhYMYMr2VmjAH8D6X0tf/e3r2Zl5qK+kjnnVVl6u7dPqtWVpZQJBcrWmPeZrxWnrBdgs6bpKQkrr32Wv7+97+Tl5dHTExMqJtkqin36Jey8Da5x1PJseLu16jMPHyofgGUVqPGW8oMYPLOncXq7diqUsEVMT10txEjRnD06FE+/fTTUDfFRJjSgpivUTS+ZstODNO68lD8XEv2uH+5cyfjd+woNhv2dtdi4N6Kp50qLOS2zEzrsQdBRPXQAQYNGkSdOnV45513GDhwYKibYyKIv7VX3eUMvHH3PL1d5O3ToEGp+fnqRnAG6dZr13pdsNtzDVi3PAA/5+YO874W/G7scIBI0C/MRtqInoi5KOpp7NixvP322+zYsaNoqTpjKsrXiJeE6GievfDCSgkwJwsKgjJrtrJU1oXfBIej2ILfJZX3wqzn++utoFo4XPCtEaNcPO3bt4/27dszYsQI3njjjUp5DVMzVXWPrjwVJ93DL6NWrozIUTZuZV085Jc7dzI7K6vU98TfcatDj95fQI+4lAtAq1at+M1vfsMTTzzB4MGDGTt2bKibZCJEeS6mVvT1oHi6ZmhCAh/m5HgdGumZ+vGXIooE+1xVOeHc9+et7OyifH0UZSuW5j5uyc+55JdrdbygG5E9dID8/HwGDRrE2rVrWbduHR07dqy01zImVPz1GP317t01ccIhZx8K3lIv1WWZwRqXcnE7dOgQnTp1IjExkS+++ILYSh4TbEx147mYtwPnxcdWsecu9r3fNSLF/FfJQO0rhSXAvNRUr8M0KyM9U2MDOsCSJUsYNmwYw4YN480336Ru3bqV/prGhKNwrltTWTy//Mry/nhL8wTrgmuNmCnqy9VXX82sWbNYsmQJt99+e6ibY0y15Wu8fLDEhWHRvH25uUXVK4cmJAT8fnjL2Vd0hm0gIj6gg3NVoyeeeIK33nqLDz74INTNMaZa8lUSIRjlC1rFxnLysst43aMcQjiF95z8fGZnZdG7fn0cFTjOvtxcmqxZU2mTqCI+5eJ29uxZ0tLS2LlzJxMnTuT//u//cDgq8tEYUzMEWnZ4wvnn06dBg4ALn3nm9wMZzx4nwinVkOb6gz3uvjxpmBqdcnGrVasW//jHP0hPT+fZZ5/lySefDHWTjAkL3nruJRcVmZeayqy2bctU+MxbITN/i5acvOwy5qWmlisNFKxfA8H+Mgl2GqbUHrqI1AZWAbE4x60vVNXHSuwTC8wF0oAcYJSq7vV33KruobupKrfeeitvvvkmn376KX369KnyNhhjys+zZ18a90iVkjNE3WUEoiAoi5FXhACFAwYEvn9FRrmIc/mfOFU9KSIxwBpgsqr+y2OfXwKdVHWCiIwGRqjqKH/HDVVABzh+/Dhdu3YlPz+fu+++G4Dhw4fTrl27kLTHGFN2pY06CSSdUR1m05Z1HHuFUi7qdNJ1N8b1p+R7cC3wmuv2QuBKqcbrwNWvX58FCxaQlZXFlClTmDJlCmlpaWRblTdjwoa3UTnuoFNajXu3sqwzWxkEfBZ1K4+AklEi4hCRTcAhYJmq/rvELknAtwCqmg8cAxK8HGe8iKwXkfWHDx+uUMMrqkePHmzdupWsrCw2b97M6dOneeqpp4oe37NnD5s2bQpdA40xfnnL189LTUU9Fhwvjb8vhUC59y/rEAv3heRglg0o0ygXEWkIvAfco6pbPbZvBQar6gHX/W+AXqr6g69jhTLl4s3YsWNZsGAB7du3Z9asWdx///3s2bOHrKwsoqMjsuSNMYZzyyeULAnsjXviUMlZt/7WYw1WCeCgFedS1aMi8gkwGNjq8dBBoCVwQESigQY4L46GjT/84Q/k5+ezfPlyxowZw969ewH49NNPufLKK0PbOGNMpfFWcM2zTn1jh4MzhYXF6t4U8t9CaO7n+qt7X1UCuSjaFMhzBfM6wFLgj6q62GOfSUBHj4ui16vqTf6OW9166G6zZ89m4sSJ1KlTh6ioKNLT0/nrX/8a6mYZY0KouhTmgoqPQz8P+ERENgPrcObQF4vI4yIy3LXPS0CCiOwCfg08GIyGh8Ltt9/Oz372MzIyMrjmmmuYO3cunTt3ZuHChaFumjEmRHwtP1jasoRVrdSUi6puBrp62f6ox+0zwI3BbVpoxMbGsmXLFmJiYti4cSPHjh3jwIED3HjjjTzyyCM8/vjjVOMBPMaYSuCrtnyoR8mUVGNmipZF7dq1cTgc9OjRgw8//JD169dzxx138Ic//IGrr76aCRMmcPHFF3Pffffx448/hrq5xphK5qtwWTCHHAaDDd8IQK1atXjhhRe44IILmDlzJitWrKBXr178+c9/5ocffmDevHmhbqIxphJVhwuegagxxbmCpaCggLy8PGrXrs3UqVP5n//5H2bMmEGHDh3o37+/1Vs3xlSqGr3ARWU6efIkXbt2ZdeuXYAz/96rVy9EhJtuuomJEydavt0YE1RWbbGSxMfHs3nzZnbv3s3SpUuZNGkSZ8+e5ciRI0yaNIl+/fqxYsWKUDfTGFNDWA+9EqgqL774Io8//jhZWVksXLiQQYMG8cgjj9C4cWPuueceGjVqFOpmGmPCkKVcQuSnn35i4MCBfPHFFzRo0ICjR4+iqtSvX5+rrrqKXbt2ce+99zJs2DASEhKICuJyX8aYyGQplxCJi4tjyZIlPPLIIwwePJhly5axadMmBg0axKpVq8jLy2PcuHE0a9aMK664gvz8fADOnDnDqFGj+OMf/wg4V1v64QefZXGMMQawHnpIFRQU8MYbb7Bp0yaefvpppk6dSkZGBg899FDRzNQBAwawZs0a8vPzmTlzJvfcc0+IW22MCSVLuVRzqsqoUaN4++23i7ZNnz6dlStXsm7dOjIyMti2bRv//Oc/ueWWW2jUqBHnnXceiYmJLFmyhOzsbNLT05kwYUIIz8IYUxUsoIeBvLw8li9fzp49exg4cCBt27aloKCAgoICatWqxYkTJ7jlllvYvHkzx44d49ixYwAkJSXRsGFDvvrqK2666SZiYmL4/e9/zwUXXBDiMzLGVAYL6BHoxx9/ZN++fXTs2JGCggLS09NZunQphYWFqCpTp05lwoQJNGrUiHfffZe//OUvPP/887Rt2zbUTTfGVIAF9BpCVTlw4AB3330377//PiJCs2bNipbWa9WqFbfccgtDhw6lR48e7Nu3r1iA/+abb9i2bRvXXHNNqE7BGFMKC+g10Lp16/joo484cOAArVq14oorruCGG24oCu7NmzcnKyuLO+64g0aNGpGUlMT//u//kp2dzdy5c/n5z39Os2bNQnwWxpiSLKCbIidPnmTSpEns2rWLDh068MILLxATE0NeXh7NmjWjTZs2/PvfziVj09PTueOOO8jMzOT06dM0a9aM4cOH06BBg4Bf78svvyQmJoaLL74YVeXvf/87V1xxBfXr16+sUzQmollANz4dP36c+Ph4MjMzadiwIbVr1+bll1/mwIEDzJw585z9GzZsSKdOnahTpw7x8fHUqVOHgwcP0rBhQwYNGsTgwYPZv39/0S+BsWPH0qBBA3bu3Mn8+fOZNGkSGRkZvPzyy3z22Wds2bKFiy++mCVLljB06FD69+9f1W+BMWHFAropl9WrV3P06FHS0tKIi4tj+/btPPfcc3z77becPn2aEydOcOrUKc4//3wOHTrEN998c84xWrVqxf79+7niiiv4/PPPcTgc/PTTT3Tp0oUvv/yy2L7R0dGMGTOGWrVqERsbS5cuXViwYAG1a9fmvvvuY8CAAVV05sZUXxbQTaVTVdasWUNmZiZt2rShadOmfP3111x22WU8/vjjPP/88/Tp04c5c+bQr18/RIQnn3yS/v37s2nTJrp168Zvf/tb1qxZQ1RUVLEvC1Xlhx9+YNGiRdStW5fDhw/ToEED1qxZw6FDh/j9739PYjnrUqsqOTk5NGnSJMjviDGVwwK6CamCggJOnjxZlHs/cOAAcXFxfguUnT17lv/85z906NCBs2fPcskll7Bjx45i+4gIMTExNGzYkOHDh7Ns2TIuuOACnnrqKZo1a8ann37KJ598wpEjR+jXrx+TJ08mNzeXlStX0qtXLxo0aMDYsWN5++23eeedd3j22We55pprmDx5cpnO7fjx40XncubMGWJiYnA4HOV4p4wpnQV0E/b27t3L/PnzSUtLIykpiSNHjpCUlMTp06d58MEHWb58Ob1792bTpk1Fk64AGjduTEJCAl9//TXt2rXj0KFD/Pjjj7Ro0YJWrVrx2WefUb9+fY4fP170nKeffppRo0Yxbdo0li5dygUXXEDHjh256KKL6NevH1u3bqVRo0Z069aNcePG8cEHH3DZZZdx0UUX8frrr9OpUycWL15c7MJvZmYmixcv5syZM9x55500b96cjz/+mJSUlKKho+4qna1bt2bgwIF+a+nv2bOHVq1aFSvoVlhYaAXeagB/AR1VDcmftLQ0NSZYCgsLVVX1u+++03nz5ukzzzyjGzZs0IKCAi0sLNS//vWvOmjQIM3IyNC5c+dqx44dtV27dvrcc8/pv/71L23durUuWLBAr7/+egW0fv36WqdOHb3uuuu0S5cuGh8fr0CxPyKigKanp2vHjh3V4XDogAEDNDo6Whs0aKDdu3fXp59+WkeOHFm0r4iow+HQlJQUBbRp06b63nvv6d/+9jedO3du0bFbt26tI0eO1FmzZmnr1q31rbfeUlXVo0eP6h133KGAdu7cWQcOHKg33HCDjho1SuPi4nTFihWal5enZ8+eVVXVgoIC3bJlS9H74/lelSY/P19/+OGHIH9SpqKA9eojrlpAN8ZDfn6+Tp48WTt37qxbtmwp2l5YWKjr16/XOXPm6Lp163TZsmV677336p///OeifQoKClRVdcWKFXrXXXdpp06dFNDGjRvrQw89pFlZWbpr1y59+OGH9aqrrtLp06drQkJCsS+JHj166KxZs3TUqFHasGFDBdThcGhiYqI+9NBDGhcXpyKid955p3bu3FnT0tK0efPmWqdOHU1KStJGjRoVHTMpKUl/9rOfKaAPP/ywFhYW6t13361t2rTRd999Vy+99FJ99dVXi9p/5swZfeWVV3TOnDl68OBBHT16tMbFxenWrVt12bJl+tJLL2nfvn01LS1N9+/fX+x927hxo/7tb38L+MvClJ+/gF5qykVEWgJzgUTXP7o5qvpsiX0GAH8H9rg2vauqj/s7rqVcTKRTVXbs2EFKSgq1atXyus+2bdvYtm0bMTExvPzyy/zpT3+iXbt2ABw5coQVK1aQlJREnz59UFVGjx7NlClT6Nq1a9Ex3Ovc7t+/n6uuuopu3brRuXNnduzYwffff09cXByLFy8mLS2NDRs2ULt2bc6cOYPD4aCgoIArr7yS5ORktmzZgvv/ZL169Thx4gTR0dFER0dz5swZAFq0aMHx48epVasWo0ePJiEhgY0bN7J48WJUlQkTJvD0009Tp04dABYtWsTs2bO54IILuP/++/n000957bXXOHv2LK+88gozZsygf//+HD16lKVLl3Lo0CHi4uKoX78+kyZNYtCgQUXnefDgQV566SUSExMZMmQIOTk5XHTRRWzevJnU1FTi4+PJycnh9ddfp1atWtx44400adKE3NxcvvjiC1q1akVycrLPz+vUqVOcPn26KEU3YcIEhgwZwv3331+tlpKsUMoFOA/o5rpdD9gJXFRinwHA4tKO5fnHeujGBO7111/XxYsXl+u5ubm5OmHCBO3du7c++uijum3bNh0/frx+/fXXOnnyZO3Zs6c2b95cExIS9O2339YNGzZohw4d9PLLL9elS5dqamqqzp49W7/++mvNzc3VLVu26PDhw7VWrVoKaJs2bXTKlCn6wAMPKKCJiYk6ZMgQHThwoALasmVLrVu3rjocDgW0Q4cOWrt2bY2Kiir26+Siiy7Sq666Svv27atJSUkaExOjL774oh46dEinTZumsbGxPtNevXv31vfee0+TkpKKHktOTtYlS5boVVddVbTtgQce0Lvvvlv79u2rN9xwg/7mN7/Rdu3aaXp6urZs2VLPO+88Xb16tTZo0ECjo6OLUmqrV6/WdevWadeuXXXw4MGakZGhY8aM0dGjR2vTpk31uuuu0/Xr1+v333+vq1at0u+++06ffPJJffLJJzUzM1NVA091lYZgplxw9sQHldhmAd2YMFcyz56fn1/q/nl5ecW2rVq1Sm+44QZNS0vTnj176j333KOnT5/Wffv26c0336x//vOftaCgQBctWqTt2rXTZcuW6eLFi3X16tXFjnP06FHt27dvseA9evRo3b17ty5fvlyfe+45nT9/vv72t7/V3//+90WBvW3btvrFF1/o2rVrtVWrVkXP/eMf/1h07cHhcGi/fv00OTlZAb300ku1du3a2qZNG42KiipKcX3zzTc6ZcoUrVu3btFxWrRooW3bttWWLVtqcnKyNmnSREeOHKlNmzbV6OhojYuLO+dLp379+jpixAhNSEjQDz/8UO+77z5dvnx5uT+noAV0oDWwH6hfYvsAIAf4D/AR0MHH88cD64H1ycnJ5T4hY0zkKygo0IULF+q0adN048aNfvd9++23dfbs2Zqbm1u07fTp0/rWW2/pu+++q6rOL6CFCxfq1q1bi+4fO3ZMVVVPnTql+fn5+sADD6iI6Mcff1x0nBMnTujcuXP1gQce0KysLK+vf+TIER0zZozeeOON+sYbb+jDDz+s27Zt071792rbtm21Vq1a2qJFi6Ig/8QTT5T7ffEX0AMetigi8cCnwHRVfbfEY/WBQlU9KSJDgWdV9UJ/x7McujGmuiksLOTgwYO0bNkyaMc8ceIEx48fJzo6mieeeIL09HR69+5d7uNVeBy6iMQAi4GPVfXpAPbfC3RXVZ8LYVpAN8aYsqvQItHivLz7EpDpK5iLSHPXfohIT9dxc8rfZGOMMWUVHcA+fYAxwBYR2eTa9jCQDKCqs4GRwEQRyQdOA6M10FyOMcaYoCg1oKvqGsDvIExVfQ54LliNMsYYU3ZW+MEYYyKEBXRjjIkQFtCNMSZCWEA3xpgIYQHdGGMiRMgWuBCRw8C+cj69CeBz0lIEq4nnbedcM9g5B66Vqjb19kDIAnpFiMh6XzOlIllNPG8755rBzjk4LOVijDERwgK6McZEiHAN6HNC3YAQqYnnbedcM9g5B0FY5tCNMcacK1x76MYYY0qwgG6MMREi7AK6iAwWkR0isktEHgx1eyqLiOwVkS0isklE1ru2NRaRZSLytevvRqFuZ0WIyMsickhEtnps83qO4jTT9blvFpFuoWt5+fk452kictD1WW9yrfrlfuwh1znvEJGfh6bVFSMiLUXkExHZJiJfichk1/aI/az9nHPlfta+1qarjn8AB/ANkALUwrmG6UWhblclneteoEmJbX8CHnTdfhD4Y6jbWcFz7A90A7aWdo7AUJzr1QpwCfDvULc/iOc8DXjAy74Xuf6NxwJtXP/2HaE+h3Kc83lAN9ftesBO17lF7Gft55wr9bMOtx56T2CXqu5W1bPAAuDaELepKl0LvOa6/RpwXeiaUnGqugo4UmKzr3O8FpirTv8CGorIeVXS0CDycc6+XAssUNVcVd0D7ML5fyCsqOp3qrrRdfsEkAkkEcGftZ9z9iUon3W4BfQk4FuP+wfw/yaFMwWWisgGERnv2paoqt+5bn8PJIamaZXK1zlG+md/tyu98LJHKi3izllEWgNdgX9TQz7rEucMlfhZh1tAr0n6qmo3YAgwSUT6ez6ozt9pET3mtCaco8tfgAuALsB3wP+FtDWVRETigXeAX6nqcc/HIvWz9nLOlfpZh1tAPwi09LjfwrUt4qjqQdffh4D3cP78ynb/9HT9fSh0Law0vs4xYj97Vc1W1QJVLQRe4L8/tSPmnEUkBmdgm6+q77o2R/Rn7e2cK/uzDreAvg64UETaiEgtYDTwfojbFHQiEici9dy3gauArTjP9TbXbrcBfw9NCyuVr3N8HxjrGgFxCXDM4+d6WCuRHx6B87MG5zmPFpFYEWkDXAh8UdXtqygREeAlIFNVn/Z4KGI/a1/nXOmfdaivBpfj6vFQnFeMvwGmhro9lXSOKTiveP8H+Mp9nkAC8E/ga2A50DjUba3gef4N58/OPJw5wzt8nSPOEQ/Puz73LUD3ULc/iOc8z3VOm13/sc/z2H+q65x3AENC3f5ynnNfnOmUzcAm15+hkfxZ+znnSv2sbeq/McZEiHBLuRhjjPHBAroxxkQIC+jGGBMhLKAbY0yEsIBujDERwgK6McZECAvoxhgTIf4/sBSHSADJZkIAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model\n"
      ],
      "metadata": {
        "id": "R19IJQSYoW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/MyDrive/All_File_Lt/Model/Classification/Male/', exist_ok=True)\n",
        "model.save('/content/drive/MyDrive/All_File_Lt/Model/Classification/Male/M1_Freeze_250_Lt.h5')"
      ],
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/11_รอบแรก_Flimpano_Female125_250.h5')"
      ],
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xlsuaFIUVriv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}