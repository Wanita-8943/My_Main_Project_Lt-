{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/My_Main_Project_Lt-/blob/main/F1_Train_Freeze_250.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เรียกใช้ CSV"
      ],
      "metadata": {
        "id": "ow7eWoNw6U-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8o_VVNXzcL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "18671720-a242-4f64-8a6d-56ef386512e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/All_File_Lt/Data/All_Data_Lt.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "mbLFqTO1ze9O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "outputId": "80735f56-b6b2-4dc5-d545-a09c2e08b002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person Class_Age+Gender Class_Age  Class_0-18  Age(year)  \\\n",
              "0           1           1             Y07F       Y07           0          7   \n",
              "1           2           1             Y07F       Y07           0          7   \n",
              "2           3           2             Y07F       Y07           0          7   \n",
              "3           4           2             Y07F       Y07           0          7   \n",
              "4           5           3             Y07F       Y07           0          7   \n",
              "...       ...         ...              ...       ...         ...        ...   \n",
              "4745      121          77             Y25M       Y25          18         25   \n",
              "4746      122          78             Y25M       Y25          18         25   \n",
              "4747      123          78             Y25M       Y25          18         25   \n",
              "4748      124          79             Y25M       Y25          18         25   \n",
              "4749      125          79             Y25M       Y25          18         25   \n",
              "\n",
              "      Class_0-1       Filename  \\\n",
              "0             0         V1.jpg   \n",
              "1             0    Flip_V1.jpg   \n",
              "2             0         V2.jpg   \n",
              "3             0    Flip_V2.jpg   \n",
              "4             0         V3.jpg   \n",
              "...         ...            ...   \n",
              "4745          1  Flip_J463.jpg   \n",
              "4746          1       J464.jpg   \n",
              "4747          1  Flip_J464.jpg   \n",
              "4748          1       J465.jpg   \n",
              "4749          1  Flip_J465.jpg   \n",
              "\n",
              "                                          Path_filename     Sex Floder  \n",
              "0     /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female   Both  \n",
              "1     /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female   Both  \n",
              "2     /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female   Both  \n",
              "3     /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female   Both  \n",
              "4     /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female   Both  \n",
              "...                                                 ...     ...    ...  \n",
              "4745  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...    Male   Both  \n",
              "4746  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...    Male   Both  \n",
              "4747  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...    Male   Both  \n",
              "4748  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...    Male   Both  \n",
              "4749  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...    Male   Both  \n",
              "\n",
              "[4750 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-477fa9cf-5fa3-47b2-9618-c229d7382895\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person</th>\n",
              "      <th>Class_Age+Gender</th>\n",
              "      <th>Class_Age</th>\n",
              "      <th>Class_0-18</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class_0-1</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>V3.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4745</th>\n",
              "      <td>121</td>\n",
              "      <td>77</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_J463.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4746</th>\n",
              "      <td>122</td>\n",
              "      <td>78</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4747</th>\n",
              "      <td>123</td>\n",
              "      <td>78</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4748</th>\n",
              "      <td>124</td>\n",
              "      <td>79</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4749</th>\n",
              "      <td>125</td>\n",
              "      <td>79</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4750 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-477fa9cf-5fa3-47b2-9618-c229d7382895')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-477fa9cf-5fa3-47b2-9618-c229d7382895 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-477fa9cf-5fa3-47b2-9618-c229d7382895');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "5qxePnnn7TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ],
      "metadata": {
        "id": "RooqSdBc7QHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 250\n",
        "NUM_TRAIN = 1425\n",
        "NUM_TEST = 475\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "98a6262f-19f9-4a5c-8f55-a60bb5ea383a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 1085, done.\u001b[K\n",
            "remote: Counting objects: 100% (248/248), done.\u001b[K\n",
            "remote: Compressing objects: 100% (127/127), done.\u001b[K\n",
            "remote: Total 1085 (delta 124), reused 241 (delta 121), pack-reused 837\u001b[K\n",
            "Receiving objects: 100% (1085/1085), 14.09 MiB | 20.79 MiB/s, done.\n",
            "Resolving deltas: 100% (621/621), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "Gqg_EUxrKkcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "uhCmH24AKmQ4",
        "outputId": "ef41743f-f2a1-407c-c83b-175b1abb4397",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "id": "IIWHby0gKpEq",
        "outputId": "a8d1ae62-0cd6-4eb9-a9c7-08296f240203",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(19, activation='softmax', name=\"fc_out\"))"
      ],
      "metadata": {
        "id": "yWNKfQUt5rga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "NadBB12251jh",
        "outputId": "08c6a25a-41ba-45ac-811e-cfd441015d70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 4,031,887\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "GepWq3yy53t5",
        "outputId": "a9153055-5ffe-4944-8c43-7005f233fe45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 213\n",
            "This is the number of trainable layers after freezing the conv base: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "D-CwVu9LrNkg",
        "outputId": "37800f94-7b37-4c97-d3f2-b66c00c56b87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 24,339\n",
            "Non-trainable params: 4,049,564\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Valodation และ Test"
      ],
      "metadata": {
        "id": "J36J9EAE7qSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Female = df[(df['Sex'] == 'Female')]"
      ],
      "metadata": {
        "id": "U7rydNfIr3Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Female"
      ],
      "metadata": {
        "id": "3LY0HbggsVJK",
        "outputId": "80888be3-8ee3-4662-f753-170e65a131d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person Class_Age+Gender Class_Age  Class_0-18  Age(year)  \\\n",
              "0           1           1             Y07F       Y07           0          7   \n",
              "1           2           1             Y07F       Y07           0          7   \n",
              "2           3           2             Y07F       Y07           0          7   \n",
              "3           4           2             Y07F       Y07           0          7   \n",
              "4           5           3             Y07F       Y07           0          7   \n",
              "...       ...         ...              ...       ...         ...        ...   \n",
              "2370      121          65             Y25F       Y25          18         25   \n",
              "2371      122          66             Y25F       Y25          18         25   \n",
              "2372      123          67             Y25F       Y25          18         25   \n",
              "2373      124          68             Y25F       Y25          18         25   \n",
              "2374      125          69             Y25F       Y25          18         25   \n",
              "\n",
              "      Class_0-1     Filename  \\\n",
              "0             0       V1.jpg   \n",
              "1             0  Flip_V1.jpg   \n",
              "2             0       V2.jpg   \n",
              "3             0  Flip_V2.jpg   \n",
              "4             0       V3.jpg   \n",
              "...         ...          ...   \n",
              "2370          0     J145.jpg   \n",
              "2371          0     J149.jpg   \n",
              "2372          0     J158.jpg   \n",
              "2373          0     J177.jpg   \n",
              "2374          0     J180.jpg   \n",
              "\n",
              "                                          Path_filename     Sex Floder  \n",
              "0     /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female   Both  \n",
              "1     /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female   Both  \n",
              "2     /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female   Both  \n",
              "3     /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female   Both  \n",
              "4     /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female   Both  \n",
              "...                                                 ...     ...    ...  \n",
              "2370  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female     Lt  \n",
              "2371  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female     Lt  \n",
              "2372  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female     Lt  \n",
              "2373  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female     Lt  \n",
              "2374  /content/drive/My Drive/All_File_Lt/TVT_All_Lt...  Female     Lt  \n",
              "\n",
              "[2375 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c62403f-97a3-41ea-a83b-80c618d67e65\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person</th>\n",
              "      <th>Class_Age+Gender</th>\n",
              "      <th>Class_Age</th>\n",
              "      <th>Class_0-18</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class_0-1</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>V3.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2370</th>\n",
              "      <td>121</td>\n",
              "      <td>65</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>J145.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2371</th>\n",
              "      <td>122</td>\n",
              "      <td>66</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>J149.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2372</th>\n",
              "      <td>123</td>\n",
              "      <td>67</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>J158.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2373</th>\n",
              "      <td>124</td>\n",
              "      <td>68</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>J177.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2374</th>\n",
              "      <td>125</td>\n",
              "      <td>69</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>J180.jpg</td>\n",
              "      <td>/content/drive/My Drive/All_File_Lt/TVT_All_Lt...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2375 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c62403f-97a3-41ea-a83b-80c618d67e65')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4c62403f-97a3-41ea-a83b-80c618d67e65 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4c62403f-97a3-41ea-a83b-80c618d67e65');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = Female[Female['Fig_Age'].between(1,75)]\n",
        "val = Female[Female['Fig_Age'].between(76,100)]"
      ],
      "metadata": {
        "id": "nqCFbjRQ3okB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/My Drive/All_File_Lt/TVT_All_Lt\"\n",
        "os.chdir(DATA_PATH)\n",
        "train_dir = os.path.join(DATA_PATH, 'train')\n",
        "print(train_dir)\n",
        "validation_dir = os.path.join(DATA_PATH, 'validation')\n",
        "print(validation_dir)"
      ],
      "metadata": {
        "id": "GsjQKrdqrQ4g",
        "outputId": "ba4d80f1-3cee-4ac2-9609-b327af7ed9f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/All_File_Lt/TVT_All_Lt/train\n",
            "/content/drive/My Drive/All_File_Lt/TVT_All_Lt/validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Train"
      ],
      "metadata": {
        "id": "bWEnlTSwazL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe = train,\n",
        "        directory = train_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Age+Gender',\n",
        "        class_mode = 'categorical',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe = val,\n",
        "        directory = validation_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Age+Gender',\n",
        "        class_mode = 'categorical',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)"
      ],
      "metadata": {
        "id": "xGPrsn9no_pa",
        "outputId": "9e7c3475-5720-457b-8844-3de332570419",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1425 validated image filenames belonging to 19 classes.\n",
            "Found 475 validated image filenames belonging to 19 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=2e-5),\n",
        "              metrics=['acc'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "N6qUmmF856ZE",
        "outputId": "ac28202b-3f79-4d65-e5d5-27baee7e3874",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-95ae5648fc7b>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "89/89 [==============================] - 252s 3s/step - loss: 4.7185 - acc: 0.0546 - val_loss: 3.9932 - val_acc: 0.0409\n",
            "Epoch 2/250\n",
            "89/89 [==============================] - 15s 163ms/step - loss: 4.3153 - acc: 0.0490 - val_loss: 3.7389 - val_acc: 0.0560\n",
            "Epoch 3/250\n",
            "89/89 [==============================] - 15s 169ms/step - loss: 4.2766 - acc: 0.0447 - val_loss: 3.6300 - val_acc: 0.0560\n",
            "Epoch 4/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 4.0734 - acc: 0.0568 - val_loss: 3.5579 - val_acc: 0.0560\n",
            "Epoch 5/250\n",
            "89/89 [==============================] - 15s 170ms/step - loss: 4.1352 - acc: 0.0532 - val_loss: 3.5209 - val_acc: 0.0625\n",
            "Epoch 6/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 4.0383 - acc: 0.0532 - val_loss: 3.4706 - val_acc: 0.0625\n",
            "Epoch 7/250\n",
            "89/89 [==============================] - 15s 166ms/step - loss: 4.0444 - acc: 0.0518 - val_loss: 3.4644 - val_acc: 0.0668\n",
            "Epoch 8/250\n",
            "89/89 [==============================] - 15s 163ms/step - loss: 3.9460 - acc: 0.0617 - val_loss: 3.4357 - val_acc: 0.0690\n",
            "Epoch 9/250\n",
            "89/89 [==============================] - 15s 170ms/step - loss: 3.9027 - acc: 0.0617 - val_loss: 3.4083 - val_acc: 0.0754\n",
            "Epoch 10/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 3.9082 - acc: 0.0724 - val_loss: 3.3892 - val_acc: 0.0776\n",
            "Epoch 11/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.8804 - acc: 0.0625 - val_loss: 3.3231 - val_acc: 0.0819\n",
            "Epoch 12/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.8684 - acc: 0.0653 - val_loss: 3.3633 - val_acc: 0.0819\n",
            "Epoch 13/250\n",
            "89/89 [==============================] - 15s 163ms/step - loss: 3.7983 - acc: 0.0774 - val_loss: 3.3603 - val_acc: 0.0841\n",
            "Epoch 14/250\n",
            "89/89 [==============================] - 15s 162ms/step - loss: 3.7015 - acc: 0.0795 - val_loss: 3.3126 - val_acc: 0.0797\n",
            "Epoch 15/250\n",
            "89/89 [==============================] - 15s 169ms/step - loss: 3.7727 - acc: 0.0774 - val_loss: 3.2987 - val_acc: 0.0948\n",
            "Epoch 16/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 3.7137 - acc: 0.0908 - val_loss: 3.2831 - val_acc: 0.0948\n",
            "Epoch 17/250\n",
            "89/89 [==============================] - 15s 170ms/step - loss: 3.7358 - acc: 0.0830 - val_loss: 3.2594 - val_acc: 0.1013\n",
            "Epoch 18/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.6528 - acc: 0.0916 - val_loss: 3.2296 - val_acc: 0.1099\n",
            "Epoch 19/250\n",
            "89/89 [==============================] - 15s 163ms/step - loss: 3.6937 - acc: 0.0859 - val_loss: 3.2027 - val_acc: 0.1034\n",
            "Epoch 20/250\n",
            "89/89 [==============================] - 15s 166ms/step - loss: 3.7573 - acc: 0.0674 - val_loss: 3.1896 - val_acc: 0.1099\n",
            "Epoch 21/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 3.6740 - acc: 0.0809 - val_loss: 3.2009 - val_acc: 0.1078\n",
            "Epoch 22/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.6461 - acc: 0.0908 - val_loss: 3.1645 - val_acc: 0.1099\n",
            "Epoch 23/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.6021 - acc: 0.0816 - val_loss: 3.1661 - val_acc: 0.1121\n",
            "Epoch 24/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 3.6685 - acc: 0.0880 - val_loss: 3.1535 - val_acc: 0.1142\n",
            "Epoch 25/250\n",
            "89/89 [==============================] - 12s 134ms/step - loss: 3.5646 - acc: 0.1022 - val_loss: 3.1329 - val_acc: 0.1185\n",
            "Epoch 26/250\n",
            "89/89 [==============================] - 15s 161ms/step - loss: 3.5565 - acc: 0.0958 - val_loss: 3.1182 - val_acc: 0.1228\n",
            "Epoch 27/250\n",
            "89/89 [==============================] - 15s 167ms/step - loss: 3.5208 - acc: 0.1036 - val_loss: 3.1287 - val_acc: 0.1121\n",
            "Epoch 28/250\n",
            "89/89 [==============================] - 15s 169ms/step - loss: 3.5756 - acc: 0.0930 - val_loss: 3.1130 - val_acc: 0.1207\n",
            "Epoch 29/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.5134 - acc: 0.0887 - val_loss: 3.1242 - val_acc: 0.1250\n",
            "Epoch 30/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.5640 - acc: 0.0937 - val_loss: 3.0775 - val_acc: 0.1293\n",
            "Epoch 31/250\n",
            "89/89 [==============================] - 15s 169ms/step - loss: 3.5477 - acc: 0.0987 - val_loss: 3.0734 - val_acc: 0.1358\n",
            "Epoch 32/250\n",
            "89/89 [==============================] - 15s 170ms/step - loss: 3.5473 - acc: 0.0880 - val_loss: 3.0877 - val_acc: 0.1293\n",
            "Epoch 33/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.4663 - acc: 0.1086 - val_loss: 3.0651 - val_acc: 0.1293\n",
            "Epoch 34/250\n",
            "89/89 [==============================] - 11s 118ms/step - loss: 3.4542 - acc: 0.1022 - val_loss: 3.0518 - val_acc: 0.1315\n",
            "Epoch 35/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 3.5016 - acc: 0.0987 - val_loss: 3.0504 - val_acc: 0.1272\n",
            "Epoch 36/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 3.4501 - acc: 0.1036 - val_loss: 3.0176 - val_acc: 0.1272\n",
            "Epoch 37/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.4578 - acc: 0.1043 - val_loss: 3.0222 - val_acc: 0.1293\n",
            "Epoch 38/250\n",
            "89/89 [==============================] - 15s 170ms/step - loss: 3.4265 - acc: 0.0944 - val_loss: 3.0133 - val_acc: 0.1293\n",
            "Epoch 39/250\n",
            "89/89 [==============================] - 15s 164ms/step - loss: 3.3885 - acc: 0.1036 - val_loss: 3.0023 - val_acc: 0.1379\n",
            "Epoch 40/250\n",
            "89/89 [==============================] - 15s 164ms/step - loss: 3.4716 - acc: 0.0908 - val_loss: 2.9934 - val_acc: 0.1336\n",
            "Epoch 41/250\n",
            "89/89 [==============================] - 15s 170ms/step - loss: 3.4099 - acc: 0.1121 - val_loss: 2.9847 - val_acc: 0.1358\n",
            "Epoch 42/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.3355 - acc: 0.1263 - val_loss: 2.9761 - val_acc: 0.1422\n",
            "Epoch 43/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.3504 - acc: 0.1072 - val_loss: 2.9669 - val_acc: 0.1336\n",
            "Epoch 44/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.4415 - acc: 0.0979 - val_loss: 2.9547 - val_acc: 0.1401\n",
            "Epoch 45/250\n",
            "89/89 [==============================] - 15s 165ms/step - loss: 3.3325 - acc: 0.1143 - val_loss: 2.9683 - val_acc: 0.1336\n",
            "Epoch 46/250\n",
            "89/89 [==============================] - 15s 165ms/step - loss: 3.4203 - acc: 0.1100 - val_loss: 2.9486 - val_acc: 0.1401\n",
            "Epoch 47/250\n",
            "89/89 [==============================] - 15s 167ms/step - loss: 3.3227 - acc: 0.1235 - val_loss: 2.9359 - val_acc: 0.1422\n",
            "Epoch 48/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.3478 - acc: 0.1114 - val_loss: 2.9197 - val_acc: 0.1444\n",
            "Epoch 49/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.2794 - acc: 0.1150 - val_loss: 2.9442 - val_acc: 0.1401\n",
            "Epoch 50/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.2713 - acc: 0.1192 - val_loss: 2.9196 - val_acc: 0.1444\n",
            "Epoch 51/250\n",
            "89/89 [==============================] - 15s 161ms/step - loss: 3.3215 - acc: 0.1107 - val_loss: 2.9001 - val_acc: 0.1401\n",
            "Epoch 52/250\n",
            "89/89 [==============================] - 15s 168ms/step - loss: 3.3483 - acc: 0.1057 - val_loss: 2.8873 - val_acc: 0.1401\n",
            "Epoch 53/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.2467 - acc: 0.1143 - val_loss: 2.8923 - val_acc: 0.1466\n",
            "Epoch 54/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.3108 - acc: 0.1221 - val_loss: 2.9001 - val_acc: 0.1487\n",
            "Epoch 55/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.3066 - acc: 0.1079 - val_loss: 2.8776 - val_acc: 0.1552\n",
            "Epoch 56/250\n",
            "89/89 [==============================] - 15s 168ms/step - loss: 3.3207 - acc: 0.1171 - val_loss: 2.8941 - val_acc: 0.1487\n",
            "Epoch 57/250\n",
            "89/89 [==============================] - 15s 162ms/step - loss: 3.2463 - acc: 0.1171 - val_loss: 2.8758 - val_acc: 0.1358\n",
            "Epoch 58/250\n",
            "89/89 [==============================] - 15s 169ms/step - loss: 3.2510 - acc: 0.1235 - val_loss: 2.8660 - val_acc: 0.1466\n",
            "Epoch 59/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.2473 - acc: 0.1299 - val_loss: 2.8586 - val_acc: 0.1530\n",
            "Epoch 60/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.2561 - acc: 0.1157 - val_loss: 2.8563 - val_acc: 0.1509\n",
            "Epoch 61/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.3372 - acc: 0.1093 - val_loss: 2.8457 - val_acc: 0.1509\n",
            "Epoch 62/250\n",
            "89/89 [==============================] - 15s 164ms/step - loss: 3.2825 - acc: 0.1136 - val_loss: 2.8419 - val_acc: 0.1552\n",
            "Epoch 63/250\n",
            "89/89 [==============================] - 15s 168ms/step - loss: 3.2501 - acc: 0.1057 - val_loss: 2.8268 - val_acc: 0.1681\n",
            "Epoch 64/250\n",
            "89/89 [==============================] - 15s 169ms/step - loss: 3.2192 - acc: 0.1292 - val_loss: 2.8184 - val_acc: 0.1681\n",
            "Epoch 65/250\n",
            "89/89 [==============================] - 15s 164ms/step - loss: 3.2036 - acc: 0.1320 - val_loss: 2.8579 - val_acc: 0.1552\n",
            "Epoch 66/250\n",
            "89/89 [==============================] - 15s 167ms/step - loss: 3.2107 - acc: 0.1278 - val_loss: 2.8247 - val_acc: 0.1552\n",
            "Epoch 67/250\n",
            "89/89 [==============================] - 15s 169ms/step - loss: 3.2573 - acc: 0.1057 - val_loss: 2.8508 - val_acc: 0.1552\n",
            "Epoch 68/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.2417 - acc: 0.1107 - val_loss: 2.8303 - val_acc: 0.1530\n",
            "Epoch 69/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.2355 - acc: 0.1164 - val_loss: 2.8347 - val_acc: 0.1552\n",
            "Epoch 70/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.1777 - acc: 0.1263 - val_loss: 2.8342 - val_acc: 0.1530\n",
            "Epoch 71/250\n",
            "89/89 [==============================] - 15s 162ms/step - loss: 3.1841 - acc: 0.1185 - val_loss: 2.8058 - val_acc: 0.1638\n",
            "Epoch 72/250\n",
            "89/89 [==============================] - 15s 168ms/step - loss: 3.2059 - acc: 0.1221 - val_loss: 2.8079 - val_acc: 0.1595\n",
            "Epoch 73/250\n",
            "89/89 [==============================] - 15s 169ms/step - loss: 3.2108 - acc: 0.1263 - val_loss: 2.7978 - val_acc: 0.1573\n",
            "Epoch 74/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.1396 - acc: 0.1334 - val_loss: 2.8089 - val_acc: 0.1616\n",
            "Epoch 75/250\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 3.2040 - acc: 0.1235 - val_loss: 2.8091 - val_acc: 0.1659\n",
            "Epoch 76/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.1123 - acc: 0.1363 - val_loss: 2.7987 - val_acc: 0.1746\n",
            "Epoch 77/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.1744 - acc: 0.1320 - val_loss: 2.7929 - val_acc: 0.1616\n",
            "Epoch 78/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.1428 - acc: 0.1299 - val_loss: 2.7838 - val_acc: 0.1703\n",
            "Epoch 79/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 3.1934 - acc: 0.1292 - val_loss: 2.7912 - val_acc: 0.1530\n",
            "Epoch 80/250\n",
            "89/89 [==============================] - 15s 165ms/step - loss: 3.1615 - acc: 0.1327 - val_loss: 2.7867 - val_acc: 0.1681\n",
            "Epoch 81/250\n",
            "89/89 [==============================] - 15s 164ms/step - loss: 3.1433 - acc: 0.1398 - val_loss: 2.7713 - val_acc: 0.1832\n",
            "Epoch 82/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.1835 - acc: 0.1228 - val_loss: 2.7545 - val_acc: 0.1746\n",
            "Epoch 83/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.0900 - acc: 0.1341 - val_loss: 2.7853 - val_acc: 0.1659\n",
            "Epoch 84/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.0776 - acc: 0.1327 - val_loss: 2.7644 - val_acc: 0.1681\n",
            "Epoch 85/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 3.1294 - acc: 0.1327 - val_loss: 2.7678 - val_acc: 0.1703\n",
            "Epoch 86/250\n",
            "89/89 [==============================] - 15s 161ms/step - loss: 3.0948 - acc: 0.1512 - val_loss: 2.7451 - val_acc: 0.1746\n",
            "Epoch 87/250\n",
            "89/89 [==============================] - 15s 166ms/step - loss: 3.0682 - acc: 0.1434 - val_loss: 2.7512 - val_acc: 0.1595\n",
            "Epoch 88/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 3.1787 - acc: 0.1136 - val_loss: 2.7617 - val_acc: 0.1573\n",
            "Epoch 89/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.0655 - acc: 0.1398 - val_loss: 2.7436 - val_acc: 0.1681\n",
            "Epoch 90/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.1247 - acc: 0.1412 - val_loss: 2.7412 - val_acc: 0.1638\n",
            "Epoch 91/250\n",
            "89/89 [==============================] - 15s 169ms/step - loss: 3.0620 - acc: 0.1285 - val_loss: 2.7410 - val_acc: 0.1681\n",
            "Epoch 92/250\n",
            "89/89 [==============================] - 15s 162ms/step - loss: 3.0591 - acc: 0.1427 - val_loss: 2.7433 - val_acc: 0.1509\n",
            "Epoch 93/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 3.0824 - acc: 0.1384 - val_loss: 2.7443 - val_acc: 0.1595\n",
            "Epoch 94/250\n",
            "89/89 [==============================] - 15s 170ms/step - loss: 3.0901 - acc: 0.1419 - val_loss: 2.7185 - val_acc: 0.1595\n",
            "Epoch 95/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.0046 - acc: 0.1370 - val_loss: 2.7104 - val_acc: 0.1681\n",
            "Epoch 96/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.0965 - acc: 0.1341 - val_loss: 2.7261 - val_acc: 0.1681\n",
            "Epoch 97/250\n",
            "89/89 [==============================] - 15s 165ms/step - loss: 3.0495 - acc: 0.1427 - val_loss: 2.7290 - val_acc: 0.1810\n",
            "Epoch 98/250\n",
            "89/89 [==============================] - 15s 167ms/step - loss: 3.0613 - acc: 0.1383 - val_loss: 2.7240 - val_acc: 0.1659\n",
            "Epoch 99/250\n",
            "89/89 [==============================] - 15s 169ms/step - loss: 3.0046 - acc: 0.1455 - val_loss: 2.7348 - val_acc: 0.1681\n",
            "Epoch 100/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.0826 - acc: 0.1441 - val_loss: 2.7241 - val_acc: 0.1724\n",
            "Epoch 101/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.0028 - acc: 0.1597 - val_loss: 2.7282 - val_acc: 0.1616\n",
            "Epoch 102/250\n",
            "89/89 [==============================] - 16s 169ms/step - loss: 3.0104 - acc: 0.1505 - val_loss: 2.7336 - val_acc: 0.1595\n",
            "Epoch 103/250\n",
            "89/89 [==============================] - 15s 162ms/step - loss: 3.0603 - acc: 0.1441 - val_loss: 2.7120 - val_acc: 0.1681\n",
            "Epoch 104/250\n",
            "89/89 [==============================] - 15s 169ms/step - loss: 3.0714 - acc: 0.1327 - val_loss: 2.7138 - val_acc: 0.1616\n",
            "Epoch 105/250\n",
            "89/89 [==============================] - 15s 169ms/step - loss: 2.9960 - acc: 0.1476 - val_loss: 2.7142 - val_acc: 0.1767\n",
            "Epoch 106/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.0716 - acc: 0.1363 - val_loss: 2.7109 - val_acc: 0.1659\n",
            "Epoch 107/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.0119 - acc: 0.1398 - val_loss: 2.6773 - val_acc: 0.1638\n",
            "Epoch 108/250\n",
            "89/89 [==============================] - 15s 166ms/step - loss: 2.9763 - acc: 0.1639 - val_loss: 2.7033 - val_acc: 0.1659\n",
            "Epoch 109/250\n",
            "89/89 [==============================] - 15s 165ms/step - loss: 2.9770 - acc: 0.1490 - val_loss: 2.6864 - val_acc: 0.1703\n",
            "Epoch 110/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 2.9821 - acc: 0.1583 - val_loss: 2.6922 - val_acc: 0.1681\n",
            "Epoch 111/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.9863 - acc: 0.1427 - val_loss: 2.7040 - val_acc: 0.1659\n",
            "Epoch 112/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.9913 - acc: 0.1242 - val_loss: 2.6898 - val_acc: 0.1703\n",
            "Epoch 113/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.9532 - acc: 0.1391 - val_loss: 2.6927 - val_acc: 0.1703\n",
            "Epoch 114/250\n",
            "89/89 [==============================] - 15s 164ms/step - loss: 3.0068 - acc: 0.1299 - val_loss: 2.7014 - val_acc: 0.1681\n",
            "Epoch 115/250\n",
            "89/89 [==============================] - 15s 169ms/step - loss: 3.0372 - acc: 0.1405 - val_loss: 2.6938 - val_acc: 0.1767\n",
            "Epoch 116/250\n",
            "89/89 [==============================] - 15s 169ms/step - loss: 2.9851 - acc: 0.1412 - val_loss: 2.7003 - val_acc: 0.1724\n",
            "Epoch 117/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.0382 - acc: 0.1270 - val_loss: 2.6917 - val_acc: 0.1703\n",
            "Epoch 118/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.9983 - acc: 0.1441 - val_loss: 2.6903 - val_acc: 0.1767\n",
            "Epoch 119/250\n",
            "89/89 [==============================] - 16s 169ms/step - loss: 2.9650 - acc: 0.1469 - val_loss: 2.6919 - val_acc: 0.1552\n",
            "Epoch 120/250\n",
            "89/89 [==============================] - 10s 107ms/step - loss: 2.8852 - acc: 0.1576 - val_loss: 2.6981 - val_acc: 0.1638\n",
            "Epoch 121/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.9102 - acc: 0.1469 - val_loss: 2.6783 - val_acc: 0.1703\n",
            "Epoch 122/250\n",
            "89/89 [==============================] - 15s 162ms/step - loss: 2.9017 - acc: 0.1675 - val_loss: 2.6719 - val_acc: 0.1638\n",
            "Epoch 123/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 2.9380 - acc: 0.1568 - val_loss: 2.6813 - val_acc: 0.1638\n",
            "Epoch 124/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.0097 - acc: 0.1398 - val_loss: 2.6699 - val_acc: 0.1659\n",
            "Epoch 125/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.9652 - acc: 0.1412 - val_loss: 2.6625 - val_acc: 0.1681\n",
            "Epoch 126/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.9462 - acc: 0.1654 - val_loss: 2.6639 - val_acc: 0.1659\n",
            "Epoch 127/250\n",
            "89/89 [==============================] - 15s 165ms/step - loss: 2.9592 - acc: 0.1483 - val_loss: 2.6494 - val_acc: 0.1681\n",
            "Epoch 128/250\n",
            "89/89 [==============================] - 15s 169ms/step - loss: 2.9431 - acc: 0.1618 - val_loss: 2.6479 - val_acc: 0.1595\n",
            "Epoch 129/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.9379 - acc: 0.1462 - val_loss: 2.6613 - val_acc: 0.1681\n",
            "Epoch 130/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.8950 - acc: 0.1675 - val_loss: 2.6588 - val_acc: 0.1724\n",
            "Epoch 131/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.9045 - acc: 0.1597 - val_loss: 2.6570 - val_acc: 0.1703\n",
            "Epoch 132/250\n",
            "89/89 [==============================] - 15s 166ms/step - loss: 2.8669 - acc: 0.1540 - val_loss: 2.6718 - val_acc: 0.1703\n",
            "Epoch 133/250\n",
            "89/89 [==============================] - 15s 164ms/step - loss: 2.9764 - acc: 0.1412 - val_loss: 2.6553 - val_acc: 0.1746\n",
            "Epoch 134/250\n",
            "89/89 [==============================] - 15s 169ms/step - loss: 2.9370 - acc: 0.1540 - val_loss: 2.6498 - val_acc: 0.1746\n",
            "Epoch 135/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.9457 - acc: 0.1455 - val_loss: 2.6608 - val_acc: 0.1789\n",
            "Epoch 136/250\n",
            "89/89 [==============================] - 15s 162ms/step - loss: 2.9073 - acc: 0.1554 - val_loss: 2.6677 - val_acc: 0.1703\n",
            "Epoch 137/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 2.9689 - acc: 0.1469 - val_loss: 2.6640 - val_acc: 0.1746\n",
            "Epoch 138/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.9051 - acc: 0.1512 - val_loss: 2.6346 - val_acc: 0.1681\n",
            "Epoch 139/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.8900 - acc: 0.1583 - val_loss: 2.6346 - val_acc: 0.1681\n",
            "Epoch 140/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.9267 - acc: 0.1483 - val_loss: 2.6439 - val_acc: 0.1789\n",
            "Epoch 141/250\n",
            "89/89 [==============================] - 15s 165ms/step - loss: 2.9211 - acc: 0.1462 - val_loss: 2.6362 - val_acc: 0.1659\n",
            "Epoch 142/250\n",
            "89/89 [==============================] - 15s 168ms/step - loss: 2.8787 - acc: 0.1554 - val_loss: 2.6347 - val_acc: 0.1659\n",
            "Epoch 143/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 2.8803 - acc: 0.1561 - val_loss: 2.6309 - val_acc: 0.1681\n",
            "Epoch 144/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.9038 - acc: 0.1505 - val_loss: 2.6513 - val_acc: 0.1659\n",
            "Epoch 145/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.8810 - acc: 0.1441 - val_loss: 2.6385 - val_acc: 0.1659\n",
            "Epoch 146/250\n",
            "89/89 [==============================] - 15s 167ms/step - loss: 2.8413 - acc: 0.1725 - val_loss: 2.6507 - val_acc: 0.1703\n",
            "Epoch 147/250\n",
            "89/89 [==============================] - 10s 110ms/step - loss: 2.8391 - acc: 0.1618 - val_loss: 2.6436 - val_acc: 0.1724\n",
            "Epoch 148/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.9412 - acc: 0.1448 - val_loss: 2.6426 - val_acc: 0.1746\n",
            "Epoch 149/250\n",
            "89/89 [==============================] - 15s 167ms/step - loss: 2.8458 - acc: 0.1654 - val_loss: 2.6178 - val_acc: 0.1703\n",
            "Epoch 150/250\n",
            "89/89 [==============================] - 10s 109ms/step - loss: 2.8377 - acc: 0.1746 - val_loss: 2.6586 - val_acc: 0.1659\n",
            "Epoch 151/250\n",
            "89/89 [==============================] - 15s 166ms/step - loss: 2.8705 - acc: 0.1498 - val_loss: 2.6443 - val_acc: 0.1767\n",
            "Epoch 152/250\n",
            "89/89 [==============================] - 15s 164ms/step - loss: 2.9158 - acc: 0.1696 - val_loss: 2.6407 - val_acc: 0.1659\n",
            "Epoch 153/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.8667 - acc: 0.1781 - val_loss: 2.6120 - val_acc: 0.1724\n",
            "Epoch 154/250\n",
            "89/89 [==============================] - 16s 169ms/step - loss: 2.8968 - acc: 0.1441 - val_loss: 2.6331 - val_acc: 0.1767\n",
            "Epoch 155/250\n",
            "89/89 [==============================] - 15s 164ms/step - loss: 2.9068 - acc: 0.1590 - val_loss: 2.6377 - val_acc: 0.1659\n",
            "Epoch 156/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 2.8733 - acc: 0.1632 - val_loss: 2.6475 - val_acc: 0.1681\n",
            "Epoch 157/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 2.8737 - acc: 0.1561 - val_loss: 2.6448 - val_acc: 0.1681\n",
            "Epoch 158/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.8322 - acc: 0.1590 - val_loss: 2.6332 - val_acc: 0.1616\n",
            "Epoch 159/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.8392 - acc: 0.1618 - val_loss: 2.6340 - val_acc: 0.1703\n",
            "Epoch 160/250\n",
            "89/89 [==============================] - 15s 164ms/step - loss: 2.8162 - acc: 0.1781 - val_loss: 2.6397 - val_acc: 0.1703\n",
            "Epoch 161/250\n",
            "89/89 [==============================] - 15s 166ms/step - loss: 2.8170 - acc: 0.1568 - val_loss: 2.6325 - val_acc: 0.1789\n",
            "Epoch 162/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 2.8977 - acc: 0.1469 - val_loss: 2.6330 - val_acc: 0.1767\n",
            "Epoch 163/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 2.8350 - acc: 0.1675 - val_loss: 2.6304 - val_acc: 0.1703\n",
            "Epoch 164/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.8698 - acc: 0.1476 - val_loss: 2.6167 - val_acc: 0.1810\n",
            "Epoch 165/250\n",
            "89/89 [==============================] - 11s 113ms/step - loss: 2.7764 - acc: 0.1583 - val_loss: 2.6453 - val_acc: 0.1832\n",
            "Epoch 166/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.8562 - acc: 0.1568 - val_loss: 2.6317 - val_acc: 0.1746\n",
            "Epoch 167/250\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 2.8563 - acc: 0.1554 - val_loss: 2.6258 - val_acc: 0.1724\n",
            "Epoch 168/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.8713 - acc: 0.1519 - val_loss: 2.6465 - val_acc: 0.1767\n",
            "Epoch 169/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 2.7911 - acc: 0.1739 - val_loss: 2.6377 - val_acc: 0.1724\n",
            "Epoch 170/250\n",
            "89/89 [==============================] - 15s 166ms/step - loss: 2.8279 - acc: 0.1611 - val_loss: 2.6236 - val_acc: 0.1810\n",
            "Epoch 171/250\n",
            "89/89 [==============================] - 15s 167ms/step - loss: 2.7589 - acc: 0.1718 - val_loss: 2.6150 - val_acc: 0.1767\n",
            "Epoch 172/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 2.8033 - acc: 0.1512 - val_loss: 2.6179 - val_acc: 0.1746\n",
            "Epoch 173/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.8619 - acc: 0.1462 - val_loss: 2.6193 - val_acc: 0.1789\n",
            "Epoch 174/250\n",
            "89/89 [==============================] - 11s 117ms/step - loss: 2.8568 - acc: 0.1654 - val_loss: 2.6105 - val_acc: 0.1746\n",
            "Epoch 175/250\n",
            "89/89 [==============================] - 11s 117ms/step - loss: 2.8442 - acc: 0.1483 - val_loss: 2.6307 - val_acc: 0.1724\n",
            "Epoch 176/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.7435 - acc: 0.1824 - val_loss: 2.6355 - val_acc: 0.1789\n",
            "Epoch 177/250\n",
            "89/89 [==============================] - 11s 116ms/step - loss: 2.8074 - acc: 0.1526 - val_loss: 2.6287 - val_acc: 0.1724\n",
            "Epoch 178/250\n",
            "89/89 [==============================] - 15s 168ms/step - loss: 2.8302 - acc: 0.1533 - val_loss: 2.6110 - val_acc: 0.1746\n",
            "Epoch 179/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 2.8236 - acc: 0.1710 - val_loss: 2.6307 - val_acc: 0.1724\n",
            "Epoch 180/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.7942 - acc: 0.1810 - val_loss: 2.6266 - val_acc: 0.1703\n",
            "Epoch 181/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 2.8045 - acc: 0.1668 - val_loss: 2.6215 - val_acc: 0.1789\n",
            "Epoch 182/250\n",
            "89/89 [==============================] - 15s 167ms/step - loss: 2.7888 - acc: 0.1710 - val_loss: 2.6318 - val_acc: 0.1659\n",
            "Epoch 183/250\n",
            "89/89 [==============================] - 15s 162ms/step - loss: 2.7975 - acc: 0.1725 - val_loss: 2.6278 - val_acc: 0.1832\n",
            "Epoch 184/250\n",
            "89/89 [==============================] - 15s 168ms/step - loss: 2.8068 - acc: 0.1625 - val_loss: 2.6177 - val_acc: 0.1810\n",
            "Epoch 185/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.8046 - acc: 0.1739 - val_loss: 2.6183 - val_acc: 0.1789\n",
            "Epoch 186/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.8113 - acc: 0.1710 - val_loss: 2.6308 - val_acc: 0.1810\n",
            "Epoch 187/250\n",
            "89/89 [==============================] - 11s 118ms/step - loss: 2.8395 - acc: 0.1576 - val_loss: 2.6430 - val_acc: 0.1767\n",
            "Epoch 188/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.7484 - acc: 0.1753 - val_loss: 2.6219 - val_acc: 0.1724\n",
            "Epoch 189/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.8096 - acc: 0.1774 - val_loss: 2.6265 - val_acc: 0.1789\n",
            "Epoch 190/250\n",
            "89/89 [==============================] - 15s 165ms/step - loss: 2.7722 - acc: 0.1632 - val_loss: 2.6285 - val_acc: 0.1832\n",
            "Epoch 191/250\n",
            "89/89 [==============================] - 15s 166ms/step - loss: 2.7552 - acc: 0.1831 - val_loss: 2.6329 - val_acc: 0.1832\n",
            "Epoch 192/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.7514 - acc: 0.1583 - val_loss: 2.6130 - val_acc: 0.1789\n",
            "Epoch 193/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.7703 - acc: 0.1746 - val_loss: 2.6143 - val_acc: 0.1832\n",
            "Epoch 194/250\n",
            "89/89 [==============================] - 16s 179ms/step - loss: 2.7761 - acc: 0.1590 - val_loss: 2.5984 - val_acc: 0.1810\n",
            "Epoch 195/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 2.7706 - acc: 0.1639 - val_loss: 2.5904 - val_acc: 0.1810\n",
            "Epoch 196/250\n",
            "89/89 [==============================] - 15s 165ms/step - loss: 2.7769 - acc: 0.1568 - val_loss: 2.6008 - val_acc: 0.1832\n",
            "Epoch 197/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.7913 - acc: 0.1689 - val_loss: 2.6089 - val_acc: 0.1746\n",
            "Epoch 198/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.7699 - acc: 0.1760 - val_loss: 2.5996 - val_acc: 0.1832\n",
            "Epoch 199/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 2.7593 - acc: 0.1902 - val_loss: 2.5944 - val_acc: 0.1875\n",
            "Epoch 200/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.7495 - acc: 0.1760 - val_loss: 2.6135 - val_acc: 0.1789\n",
            "Epoch 201/250\n",
            "89/89 [==============================] - 15s 162ms/step - loss: 2.7758 - acc: 0.1647 - val_loss: 2.6143 - val_acc: 0.1767\n",
            "Epoch 202/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 2.7671 - acc: 0.1625 - val_loss: 2.6211 - val_acc: 0.1789\n",
            "Epoch 203/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.7258 - acc: 0.1767 - val_loss: 2.5887 - val_acc: 0.1767\n",
            "Epoch 204/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.7375 - acc: 0.1710 - val_loss: 2.5887 - val_acc: 0.1897\n",
            "Epoch 205/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.7591 - acc: 0.1654 - val_loss: 2.5966 - val_acc: 0.1832\n",
            "Epoch 206/250\n",
            "89/89 [==============================] - 15s 166ms/step - loss: 2.7677 - acc: 0.1781 - val_loss: 2.5979 - val_acc: 0.1767\n",
            "Epoch 207/250\n",
            "89/89 [==============================] - 15s 163ms/step - loss: 2.7193 - acc: 0.1732 - val_loss: 2.6047 - val_acc: 0.1832\n",
            "Epoch 208/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 2.7186 - acc: 0.1746 - val_loss: 2.6012 - val_acc: 0.1832\n",
            "Epoch 209/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.7499 - acc: 0.1739 - val_loss: 2.6045 - val_acc: 0.1789\n",
            "Epoch 210/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.7640 - acc: 0.1732 - val_loss: 2.6043 - val_acc: 0.1853\n",
            "Epoch 211/250\n",
            "89/89 [==============================] - 17s 183ms/step - loss: 2.7589 - acc: 0.1639 - val_loss: 2.5957 - val_acc: 0.1875\n",
            "Epoch 212/250\n",
            "89/89 [==============================] - 10s 110ms/step - loss: 2.7692 - acc: 0.1838 - val_loss: 2.6067 - val_acc: 0.1724\n",
            "Epoch 213/250\n",
            "89/89 [==============================] - 15s 166ms/step - loss: 2.7457 - acc: 0.1789 - val_loss: 2.5956 - val_acc: 0.1810\n",
            "Epoch 214/250\n",
            "89/89 [==============================] - 10s 111ms/step - loss: 2.7533 - acc: 0.1767 - val_loss: 2.6206 - val_acc: 0.1853\n",
            "Epoch 215/250\n",
            "89/89 [==============================] - 15s 165ms/step - loss: 2.7607 - acc: 0.1703 - val_loss: 2.5945 - val_acc: 0.1810\n",
            "Epoch 216/250\n",
            "89/89 [==============================] - 15s 165ms/step - loss: 2.7253 - acc: 0.1760 - val_loss: 2.6119 - val_acc: 0.1810\n",
            "Epoch 217/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.6451 - acc: 0.1831 - val_loss: 2.5904 - val_acc: 0.1918\n",
            "Epoch 218/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.7307 - acc: 0.1902 - val_loss: 2.5942 - val_acc: 0.1810\n",
            "Epoch 219/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 2.6994 - acc: 0.1817 - val_loss: 2.5915 - val_acc: 0.1832\n",
            "Epoch 220/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 2.7440 - acc: 0.1718 - val_loss: 2.5851 - val_acc: 0.1810\n",
            "Epoch 221/250\n",
            "89/89 [==============================] - 15s 164ms/step - loss: 2.7100 - acc: 0.1767 - val_loss: 2.6164 - val_acc: 0.1767\n",
            "Epoch 222/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 2.6594 - acc: 0.1881 - val_loss: 2.6166 - val_acc: 0.1853\n",
            "Epoch 223/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.6816 - acc: 0.1874 - val_loss: 2.5900 - val_acc: 0.1897\n",
            "Epoch 224/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.6959 - acc: 0.1696 - val_loss: 2.6253 - val_acc: 0.1832\n",
            "Epoch 225/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.7376 - acc: 0.1675 - val_loss: 2.5822 - val_acc: 0.1897\n",
            "Epoch 226/250\n",
            "89/89 [==============================] - 10s 106ms/step - loss: 2.7328 - acc: 0.1696 - val_loss: 2.6086 - val_acc: 0.1853\n",
            "Epoch 227/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.6745 - acc: 0.1973 - val_loss: 2.5919 - val_acc: 0.1918\n",
            "Epoch 228/250\n",
            "89/89 [==============================] - 15s 165ms/step - loss: 2.7581 - acc: 0.1682 - val_loss: 2.5914 - val_acc: 0.1853\n",
            "Epoch 229/250\n",
            "89/89 [==============================] - 15s 169ms/step - loss: 2.7090 - acc: 0.1881 - val_loss: 2.6036 - val_acc: 0.1875\n",
            "Epoch 230/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.6954 - acc: 0.1796 - val_loss: 2.5851 - val_acc: 0.1875\n",
            "Epoch 231/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.7197 - acc: 0.1831 - val_loss: 2.5831 - val_acc: 0.1897\n",
            "Epoch 232/250\n",
            "89/89 [==============================] - 11s 121ms/step - loss: 2.7460 - acc: 0.1597 - val_loss: 2.5842 - val_acc: 0.1875\n",
            "Epoch 233/250\n",
            "89/89 [==============================] - 15s 169ms/step - loss: 2.7157 - acc: 0.1777 - val_loss: 2.5952 - val_acc: 0.1810\n",
            "Epoch 234/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.6685 - acc: 0.1796 - val_loss: 2.5728 - val_acc: 0.1897\n",
            "Epoch 235/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.6979 - acc: 0.1838 - val_loss: 2.5738 - val_acc: 0.1940\n",
            "Epoch 236/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.7396 - acc: 0.1703 - val_loss: 2.5785 - val_acc: 0.1853\n",
            "Epoch 237/250\n",
            "89/89 [==============================] - 15s 162ms/step - loss: 2.6529 - acc: 0.1874 - val_loss: 2.5946 - val_acc: 0.1875\n",
            "Epoch 238/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.6753 - acc: 0.1909 - val_loss: 2.5744 - val_acc: 0.1961\n",
            "Epoch 239/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.6902 - acc: 0.1774 - val_loss: 2.5617 - val_acc: 0.1940\n",
            "Epoch 240/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.6648 - acc: 0.1994 - val_loss: 2.5766 - val_acc: 0.1918\n",
            "Epoch 241/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 2.6761 - acc: 0.1831 - val_loss: 2.5948 - val_acc: 0.1853\n",
            "Epoch 242/250\n",
            "89/89 [==============================] - 15s 165ms/step - loss: 2.6880 - acc: 0.1703 - val_loss: 2.5804 - val_acc: 0.1832\n",
            "Epoch 243/250\n",
            "89/89 [==============================] - 15s 164ms/step - loss: 2.6571 - acc: 0.1980 - val_loss: 2.5617 - val_acc: 0.1897\n",
            "Epoch 244/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 2.6724 - acc: 0.1803 - val_loss: 2.5546 - val_acc: 0.1875\n",
            "Epoch 245/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.6023 - acc: 0.1909 - val_loss: 2.5895 - val_acc: 0.1875\n",
            "Epoch 246/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.6913 - acc: 0.1852 - val_loss: 2.5778 - val_acc: 0.1918\n",
            "Epoch 247/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 2.6670 - acc: 0.1902 - val_loss: 2.5541 - val_acc: 0.1961\n",
            "Epoch 248/250\n",
            "89/89 [==============================] - 15s 163ms/step - loss: 2.6841 - acc: 0.1753 - val_loss: 2.5633 - val_acc: 0.1940\n",
            "Epoch 249/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.7238 - acc: 0.1810 - val_loss: 2.5448 - val_acc: 0.1983\n",
            "Epoch 250/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.6736 - acc: 0.1852 - val_loss: 2.5408 - val_acc: 0.1940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'mo', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'mo', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "8ee40613-4b82-4bef-e003-7700a8dd4efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model\n"
      ],
      "metadata": {
        "id": "R19IJQSYoW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/MyDrive/All_File_Lt/Model/Classification/', exist_ok=True)\n",
        "model.save('/content/drive/MyDrive/All_File_Lt/Model/Classification/Female/F1_Freeze_250_Lt.h5')"
      ],
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/11_รอบแรก_Flimpano_Female125_250.h5')"
      ],
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xlsuaFIUVriv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}